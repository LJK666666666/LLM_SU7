爬虫（隧道代理等方式绕过反爬虫机制）
数据集划分（8:1:1划分训练集/验证集/测试集，重复数据必定划入训练集）
重复数据检索相似程度和重复次数（对比cosine，采用Jaccard+N-gram(MinHash算法加速)；滑动窗口10000+维护全局 Top K Hash：用一个全局字典记录出现次数超过 3 次的文本的 Hash 值，这样即使窗口滑过去了，也能记住“这是个老梗”。）
小米汽车相关词汇
LDA主题分析
特征工程(评论长度, 感叹号数, 问号数, 表情数, 发布小时, 发布星期, 是否工作日, 用户总评论数, 是否认证用户, 是否一级评论, 话题标签的类别或有无, 楼层数, 小米汽车相关词汇, LDA主题, 时间顺序索引, 相似程度, 重复次数)
baseline(特征工程，ngboost)

神经网络：
使用bge-base-zh-v1.5将评论/微博/根评论/父评论的文案嵌入为向量，使用合适的神经网络架构，两个预测头同时预测均值（评论数）和方差（不确定性/模糊性），使用对数尺度的NLL损失函数。
@用户（命名实体，白名单机制： 建立一个 VIP 列表如雷军、卢伟冰、官微，保留这些ID，嵌入向量，泛化处理： 将其他所有 @用户 统一替换为特殊 Token 例如 _USER_，统一嵌入为一个特定的向量）、小米汽车相关词汇（命名实体，嵌入向量）、表情符号（嵌入向量）、特殊字符（嵌入向量）
输入：评论本身文案、微博/根评论/父评论文案、时间、作者的总评论数量、是否认证用户、是否一级评论、时间顺序索引、相似程度、重复次数
预测：评论数

多维评价指标：
维度一：解决“大数预测微小误差不应惩罚” (关注相对准确性)对于社交媒体数据（长尾分布，有的只有几个转发，有的几万个），对数误差或百分比误差是最佳选择。
1. MSLE (Mean Squared Logarithmic Error) —— 首选推荐这是 Kaggle 销量预测等长尾任务中最常用的指标。公式：$MSLE = \frac{1}{n} \sum (\log(y_{true} + 10) - \log(y_{pred} + 10))^2$为什么适合你：关注比例而非差值。两者的平方差极小，几乎不惩罚。惩罚低估多于高估（通常）：更关注数量级是否对。
2. Accuracy within X% (ACP) —— 最直观的业务指标定义一个“容忍区间”，比如 $\pm 10\%$ 或 $\pm 5\%$。定义：如果 $|y_{pred} - y_{true}| \le \text{max}(\alpha \cdot y_{true}, \delta)$，则视为“命中”。指标：计算 命中率 (Hit Rate)。为什么适合你：2000 预测成 1995，误差 0.25%，远小于 5%，直接算作“预测正确”。这比看 loss 数值直观得多，答辩时可以说：“我的模型在 $\pm 10\%$ 的误差容忍度下，准确率达到了 92%”。建议设置：$\alpha=20\%$（相对误差），$\delta=5$（绝对误差）。含义：对于大数（如 1000）：允许 $\pm 200$ 的误差（看比例）。对于小数（如 0）：允许 $\pm 5$ 的误差（看绝对值）。只要预测在 $[0, 5]$ 之间，都算对。
维度二：解决“不仅看准不准，还看方差好不好” (关注不确定性)既然你的模型输出了 $\sigma$（置信度/方差），评价指标必须能奖励那些“知道自己不知道”的模型。
1. Negative Log Likelihood (NLL) —— 学术界标准直接在测试集上计算 NLL Loss。含义：评估真实值 $y_{true}$ 在模型预测的高斯分布 $N(\mu, \sigma)$ 中的概率密度。优势：如果模型预测错得离谱（$\mu$ 偏离 $y$），但它很有自知之明地给出了很大的 $\sigma$，NLL 不会爆表；反之，如果模型盲目自信（$\sigma$ 很小）却错了，NLL 会给与重罚。改成这样：$$L = \frac{1}{2} \log(\sigma^2) + \frac{(log(y+10) - log(\mu+10))^2}{2\sigma^2}$$即对数尺度的损失。
2. Prediction Interval Coverage Probability (PICP) —— 区间覆盖率做法：利用预测的 $\mu$ 和 $\sigma$，构建一个 95% 置信区间 $[\mu - 1.96\sigma, \mu + 1.96\sigma]$。指标：统计测试集中，有多少个真实值 $y_{true}$ 落在这个区间里？目标：理论上应该接近 95%。如果 PICP < 95%：说明模型盲目自信（区间太窄，网不住真实值）。如果 PICP > 99%：说明模型过于保守/摆烂（区间给得太宽，全是废话）。引入 MPIW (Mean Prediction Interval Width) 作为辅助指标。$MPIW = \frac{1}{n} \sum (\text{Upper}_i - \text{Lower}_i)$。可以画一张图，横轴是 PICP，纵轴是 MPIW。模型应该落在“高覆盖率 + 低宽度”的黄金区域。
