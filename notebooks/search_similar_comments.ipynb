{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "总数据量: 271,452 条\n",
      "时间密度特征: 271,452 条\n"
     ]
    }
   ],
   "source": [
    "# 检索包含\"我这辈子\"的评论及其相似度特征\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 切换到项目根目录\n",
    "os.chdir(r'D:\\010_CodePrograms\\L\\LLM_su7')\n",
    "\n",
    "# 加载原始数据\n",
    "print(\"加载数据...\")\n",
    "train_df = pd.read_pickle('train.pkl')\n",
    "val_df = pd.read_pickle('val.pkl')\n",
    "test_df = pd.read_pickle('test.pkl')\n",
    "\n",
    "# 加载时间密度特征\n",
    "train_td = pd.read_pickle('train_time_density.pkl')\n",
    "val_td = pd.read_pickle('val_time_density.pkl')\n",
    "test_td = pd.read_pickle('test_time_density.pkl')\n",
    "\n",
    "# 合并所有数据\n",
    "train_df['数据集'] = 'train'\n",
    "val_df['数据集'] = 'val'\n",
    "test_df['数据集'] = 'test'\n",
    "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "# 合并时间密度特征\n",
    "all_td = pd.concat([train_td, val_td, test_td], ignore_index=True)\n",
    "print(f\"总数据量: {len(all_df):,} 条\")\n",
    "print(f\"时间密度特征: {len(all_td):,} 条\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包含\"我这辈子\"的评论数量: 17 条\n"
     ]
    }
   ],
   "source": [
    "# 将时间密度特征合并到原数据\n",
    "all_df = all_df.merge(all_td, on='序号', how='left')\n",
    "\n",
    "# 筛选包含\"我这辈子\"的评论\n",
    "keyword = '我这辈子'\n",
    "mask = all_df['评论文案'].str.contains(keyword, na=False)\n",
    "filtered_df = all_df[mask].copy()\n",
    "print(f'包含\"{keyword}\"的评论数量: {len(filtered_df):,} 条')\n",
    "\n",
    "# 按时间顺序索引排序\n",
    "filtered_df = filtered_df.sort_values('时间顺序索引').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按时间顺序显示包含\"我这辈子\"的评论:\n",
      "\n",
      "[时间索引  32062] 序号: 145210 | 相似度: 0.9020 | 重复次数:    1 | train\n",
      "  发布时间: 2025-03-31 16:12:14\n",
      "  评论: 这，可能是我这辈子开过加速最快情绪价值最高的车\n",
      "\n",
      "[时间索引  58320] 序号:   3072 | 相似度: 0.9110 | 重复次数:    2 | train\n",
      "  发布时间: 2025-04-01 23:06:29\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  59338] 序号: 256532 | 相似度: 0.9984 | 重复次数:    4 | test\n",
      "  发布时间: 2025-04-01 23:22:36\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险公司，而是找汽车商家的\n",
      "\n",
      "[时间索引  59448] 序号: 118947 | 相似度: 0.9981 | 重复次数:    3 | train\n",
      "  发布时间: 2025-04-01 23:24:21\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  59736] 序号:  16213 | 相似度: 1.0000 | 重复次数:    7 | train\n",
      "  发布时间: 2025-04-01 23:29:18\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  61065] 序号: 199354 | 相似度: 0.9662 | 重复次数:    4 | train\n",
      "  发布时间: 2025-04-01 23:57:39\n",
      "  评论: 是这样的//@身骑白马:我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  62879] 序号: 262717 | 相似度: 0.8693 | 重复次数:    0 | test\n",
      "  发布时间: 2025-04-02 00:48:58\n",
      "  评论: 是的，调查结果还没出来，就让人家车企负责[允悲]我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的，目的地太明显了，一堆傻子还在嘿嘿嘿\n",
      "\n",
      "[时间索引  66067] 序号:  90177 | 相似度: 0.9189 | 重复次数:    5 | train\n",
      "  发布时间: 2025-04-02 06:03:47\n",
      "  评论: @雷军 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的………人不能太老实\n",
      "\n",
      "[时间索引  66115] 序号: 154287 | 相似度: 0.9820 | 重复次数:    8 | train\n",
      "  发布时间: 2025-04-02 06:10:51\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商厂家的\n",
      "\n",
      "[时间索引  66557] 序号: 104247 | 相似度: 1.0000 | 重复次数:   12 | train\n",
      "  发布时间: 2025-04-02 06:42:23\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  73041] 序号: 172033 | 相似度: 0.7771 | 重复次数:    0 | train\n",
      "  发布时间: 2025-04-02 09:10:59\n",
      "  评论: 我的荣放有次跟车过近突然提醒我注意危险，我都没有发现有预碰撞提醒功能，丰田的销售也没有给我介绍。//@听龙卷风吹:雷军脾气太好了，换大众丰田试试[允悲] //@璇律66:我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  82118] 序号: 195656 | 相似度: 0.8198 | 重复次数:    0 | train\n",
      "  发布时间: 2025-04-02 11:45:31\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的----这母亲想用舆论影响结果，耐心等待调查结果吧。中国就是会哭的有奶吃，这个博弈要改改了。\n",
      "\n",
      "[时间索引  82736] 序号: 109008 | 相似度: 0.9071 | 重复次数:    4 | train\n",
      "  发布时间: 2025-04-02 11:57:10\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引  93435] 序号: 245611 | 相似度: 0.9141 | 重复次数:    2 | test\n",
      "  发布时间: 2025-04-02 15:22:38\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的[doge]\n",
      "\n",
      "[时间索引 101921] 序号: 207544 | 相似度: 0.9972 | 重复次数:    8 | train\n",
      "  发布时间: 2025-04-02 18:27:02\n",
      "  评论: 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的\n",
      "\n",
      "[时间索引 194806] 序号:  77994 | 相似度: 0.9078 | 重复次数:    4 | train\n",
      "  发布时间: 2025-04-06 16:44:24\n",
      "  评论: 我这辈子最佩服的就是雷总了，亏钱做生意都能做成首富[悲伤]\n",
      "\n",
      "[时间索引 246524] 序号:  20976 | 相似度: 0.7555 | 重复次数:    0 | train\n",
      "  发布时间: 2025-04-12 10:01:06\n",
      "  评论: 友商们别急哈，正常人可以过几个月半年蹲一下我微博，这边不是网红网黑，放心蹲哈。不正常的等我下班一个个投诉哈。我不是雷总粉丝哈，雷总好基友黑过我偶像，我这辈子都讨厌他基友，雷总是路人哈。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 显示结果\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 选择需要显示的列\n",
    "display_cols = ['时间顺序索引', '序号', '发布时间', '评论文案', '最大相似度', '重复次数', '数据集']\n",
    "result = filtered_df[display_cols]\n",
    "\n",
    "print(f'按时间顺序显示包含\"{keyword}\"的评论:\\n')\n",
    "for idx, row in result.iterrows():\n",
    "    print(f\"[时间索引 {row['时间顺序索引']:>6}] 序号: {row['序号']:>6} | 相似度: {row['最大相似度']:.4f} | 重复次数: {row['重复次数']:>4} | {row['数据集']}\")\n",
    "    print(f\"  发布时间: {row['发布时间']}\")\n",
    "    comment = str(row['评论文案'])\n",
    "    print(f\"  评论: {comment[:150]}{'...' if len(comment) > 150 else ''}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "统计信息:\n",
      "  总数量: 17 条\n",
      "  最大相似度 - 均值: 0.9191, 最大: 1.0000, 最小: 0.7555\n",
      "  重复次数 - 均值: 3.76, 最大: 12, 最小: 0\n",
      "  时间范围: 2025-03-31 16:12:14 ~ 2025-04-12 10:01:06\n"
     ]
    }
   ],
   "source": [
    "# 统计信息\n",
    "print(\"=\" * 60)\n",
    "print(f\"统计信息:\")\n",
    "print(f\"  总数量: {len(filtered_df)} 条\")\n",
    "print(f\"  最大相似度 - 均值: {filtered_df['最大相似度'].mean():.4f}, 最大: {filtered_df['最大相似度'].max():.4f}, 最小: {filtered_df['最大相似度'].min():.4f}\")\n",
    "print(f\"  重复次数 - 均值: {filtered_df['重复次数'].mean():.2f}, 最大: {filtered_df['重复次数'].max()}, 最小: {filtered_df['重复次数'].min()}\")\n",
    "print(f\"  时间范围: {filtered_df['发布时间'].min()} ~ {filtered_df['发布时间'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征合并完成\n",
      "BGE列: 最大相似度_bge, 重复次数_bge\n",
      "MinHash列: 最大相似度_minhash, 重复次数_minhash\n"
     ]
    }
   ],
   "source": [
    "# 加载MinHash特征进行对比\n",
    "train_td_mh = pd.read_pickle('train_time_density_minhash.pkl')\n",
    "val_td_mh = pd.read_pickle('val_time_density_minhash.pkl')\n",
    "test_td_mh = pd.read_pickle('test_time_density_minhash.pkl')\n",
    "all_td_mh = pd.concat([train_td_mh, val_td_mh, test_td_mh], ignore_index=True)\n",
    "\n",
    "# 重新加载原始数据\n",
    "train_df = pd.read_pickle('train.pkl')\n",
    "val_df = pd.read_pickle('val.pkl') \n",
    "test_df = pd.read_pickle('test.pkl')\n",
    "train_df['数据集'] = 'train'\n",
    "val_df['数据集'] = 'val'\n",
    "test_df['数据集'] = 'test'\n",
    "all_df_new = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "# 合并BGE和MinHash特征\n",
    "all_df_new = all_df_new.merge(all_td, on='序号', how='left', suffixes=('', '_bge'))\n",
    "all_df_new = all_df_new.merge(all_td_mh, on='序号', how='left', suffixes=('_bge', '_minhash'))\n",
    "\n",
    "print(\"特征合并完成\")\n",
    "print(f\"BGE列: 最大相似度_bge, 重复次数_bge\")\n",
    "print(f\"MinHash列: 最大相似度_minhash, 重复次数_minhash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包含\"我这辈子\"的评论: 17 条\n",
      "\n",
      "====================================================================================================\n",
      "    时间索引 |     BGE相似度 |    BGE重复 |      MH相似度 |     MH重复 | 评论摘要\n",
      "====================================================================================================\n",
      "   32062 |     0.9020 |        1 |     0.0703 |        0 | 这，可能是我这辈子开过加速最快情绪价值最高的车...\n",
      "   58320 |     0.9110 |        2 |     0.0938 |        0 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   59338 |     0.9984 |        4 |     0.8828 |        1 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险公司，而是找汽车商家的...\n",
      "   59448 |     0.9981 |        3 |     1.0000 |        2 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   59736 |     1.0000 |        7 |     1.0000 |        3 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   61065 |     0.9662 |        4 |     0.6797 |        4 | 是这样的//@身骑白马:我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   62879 |     0.8693 |        0 |     0.4453 |        0 | 是的，调查结果还没出来，就让人家车企负责[允悲]我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的，目的地太明显了，一堆傻子还在嘿嘿嘿...\n",
      "   66067 |     0.9189 |        5 |     0.7266 |        5 | @雷军 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的………人不能太老实...\n",
      "   66115 |     0.9820 |        8 |     0.9297 |        6 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商厂家的...\n",
      "   66557 |     1.0000 |       12 |     1.0000 |        8 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   73041 |     0.7771 |        0 |     0.2656 |        0 | 我的荣放有次跟车过近突然提醒我注意危险，我都没有发现有预碰撞提醒功能，丰田的销售也没有给我介绍。//@听龙卷风吹:雷军脾气太好了，换大众丰田试试[允悲] //@璇律66:我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   82118 |     0.8198 |        0 |     0.1875 |        0 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的----这母亲想用舆论影响结果，耐心等待调查结果吧。中国就是会哭的有奶吃，这个博弈要改改了。...\n",
      "   82736 |     0.9071 |        4 |     0.4453 |        0 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "   93435 |     0.9141 |        2 |     0.1875 |        0 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的[doge]...\n",
      "  101921 |     0.9972 |        8 |     0.7656 |        1 | 我这辈子第一次听说，出了交通事故在第一时间不找警察，不找保险，而是找汽车商家的...\n",
      "  194806 |     0.9078 |        4 |     0.0703 |        0 | 我这辈子最佩服的就是雷总了，亏钱做生意都能做成首富[悲伤]...\n",
      "  246524 |     0.7555 |        0 |     0.0469 |        0 | 友商们别急哈，正常人可以过几个月半年蹲一下我微博，这边不是网红网黑，放心蹲哈。不正常的等我下班一个个投诉哈。我不是雷总粉丝哈，雷总好基友黑过我偶像，我这辈子都讨厌他基友，雷总是路人哈。...\n"
     ]
    }
   ],
   "source": [
    "# 筛选包含\"我这辈子\"的评论并对比两种方法\n",
    "keyword = '我这辈子'\n",
    "mask = all_df_new['评论文案'].str.contains(keyword, na=False)\n",
    "filtered_compare = all_df_new[mask].copy()\n",
    "filtered_compare = filtered_compare.sort_values('时间顺序索引_bge').reset_index(drop=True)\n",
    "\n",
    "print(f'包含\"{keyword}\"的评论: {len(filtered_compare)} 条\\n')\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'时间索引':>8} | {'BGE相似度':>10} | {'BGE重复':>8} | {'MH相似度':>10} | {'MH重复':>8} | 评论摘要\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for idx, row in filtered_compare.iterrows():\n",
    "    time_idx = int(row['时间顺序索引_bge'])\n",
    "    bge_sim = row['最大相似度_bge']\n",
    "    bge_cnt = int(row['重复次数_bge'])\n",
    "    mh_sim = row['最大相似度_minhash']\n",
    "    mh_cnt = int(row['重复次数_minhash'])\n",
    "    comment = str(row['评论文案'])[:]\n",
    "    \n",
    "    print(f\"{time_idx:>8} | {bge_sim:>10.4f} | {bge_cnt:>8} | {mh_sim:>10.4f} | {mh_cnt:>8} | {comment}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "两种方法对比统计:\n",
      "============================================================\n",
      "\n",
      "【BGE语义相似度】(阈值=0.9)\n",
      "  平均最大相似度: 0.9191\n",
      "  平均重复次数: 3.76\n",
      "  检测到重复的评论数: 13\n",
      "\n",
      "【MinHash Jaccard相似度】(阈值=0.5, N-gram=3)\n",
      "  平均最大相似度: 0.5175\n",
      "  平均重复次数: 1.76\n",
      "  检测到重复的评论数: 8\n",
      "\n",
      "============================================================\n",
      "分析结论:\n",
      "============================================================\n",
      "\n",
      "1. BGE语义相似度能够捕捉语义相近但文字不完全相同的评论\n",
      "   - 对于完全相同的评论，相似度=1.0\n",
      "   - 对于稍有改动的评论（如添加表情、引用），相似度也很高(>0.9)\n",
      "\n",
      "2. MinHash Jaccard相似度基于字符N-gram匹配\n",
      "   - 只有文字高度重合时才会有高相似度\n",
      "   - 对于添加了前缀/后缀的评论，相似度会降低\n",
      "   - 计算速度更快，适合大规模去重任务\n",
      "\n",
      "3. 对于\"我这辈子第一次听说...\"这类复制粘贴的评论：\n",
      "   - BGE能识别更多变体（如添加@雷军、表情、引用等）\n",
      "   - MinHash只能识别几乎完全相同的文本\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 统计对比\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"两种方法对比统计:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n【BGE语义相似度】(阈值=0.9)\")\n",
    "print(f\"  平均最大相似度: {filtered_compare['最大相似度_bge'].mean():.4f}\")\n",
    "print(f\"  平均重复次数: {filtered_compare['重复次数_bge'].mean():.2f}\")\n",
    "print(f\"  检测到重复的评论数: {(filtered_compare['重复次数_bge'] > 0).sum()}\")\n",
    "\n",
    "print(f\"\\n【MinHash Jaccard相似度】(阈值=0.5, N-gram=3)\")\n",
    "print(f\"  平均最大相似度: {filtered_compare['最大相似度_minhash'].mean():.4f}\")\n",
    "print(f\"  平均重复次数: {filtered_compare['重复次数_minhash'].mean():.2f}\")\n",
    "print(f\"  检测到重复的评论数: {(filtered_compare['重复次数_minhash'] > 0).sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"分析结论:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. BGE语义相似度能够捕捉语义相近但文字不完全相同的评论\n",
    "   - 对于完全相同的评论，相似度=1.0\n",
    "   - 对于稍有改动的评论（如添加表情、引用），相似度也很高(>0.9)\n",
    "   \n",
    "2. MinHash Jaccard相似度基于字符N-gram匹配\n",
    "   - 只有文字高度重合时才会有高相似度\n",
    "   - 对于添加了前缀/后缀的评论，相似度会降低\n",
    "   - 计算速度更快，适合大规模去重任务\n",
    "   \n",
    "3. 对于\"我这辈子第一次听说...\"这类复制粘贴的评论：\n",
    "   - BGE能识别更多变体（如添加@雷军、表情、引用等）\n",
    "   - MinHash只能识别几乎完全相同的文本\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radioml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
