{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Notebook Created by Jupyter MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€åŠ è½½æ•°æ®ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯„è®ºæ•°æ®: 273,937 æ¡\n",
      "è¯„è®ºæ•°æ®åˆ—: ['åŸæ–‡é“¾æ¥', 'æ ¹è¯„è®ºID', 'çˆ¶è¯„è®ºID', 'è¯„è®ºID', 'ç”¨æˆ·ID', 'çˆ¶ç”¨æˆ·æ˜µç§°', 'ç”¨æˆ·æ˜µç§°', 'è¯„è®ºå†…å®¹', 'å‘å¸ƒæ—¶é—´', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°', 'ç”¨æˆ·è®¤è¯', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°', 'æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º', 'crawl_date', 'å†…å®¹æ¸…æ´—']\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "DATA_ROOT = 'D:/010_CodePrograms/L/LLM_su7/å°ç±³SU7æ•°æ®_2'\n",
    "RESULTS_DIR = 'D:/010_CodePrograms/L/LLM_su7/results'\n",
    "\n",
    "# 1. åŠ è½½å»é‡åçš„è¯„è®ºæ•°æ®\n",
    "print(\"ã€åŠ è½½æ•°æ®ã€‘\")\n",
    "comments_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"è¯„è®ºæ•°æ®: {len(comments_df):,} æ¡\")\n",
    "print(f\"è¯„è®ºæ•°æ®åˆ—: {list(comments_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€åŠ è½½çƒ­é—¨å¾®åšæ•°æ®ã€‘\n",
      "çƒ­é—¨å¾®åš: 4,186 æ¡\n",
      "çƒ­é—¨å¾®åšåˆ—: ['author_name', 'author_url', 'weibo_url', 'publish_time', 'weibo_content', 'repost_count', 'comment_count', 'like_count', 'crawl_date', 'å†…å®¹æ¸…æ´—']\n",
      "å¾®åšæ–‡æ¡ˆæ˜ å°„æ•°: 4,153\n"
     ]
    }
   ],
   "source": [
    "# 2. åŠ è½½çƒ­é—¨å¾®åšæ•°æ®ï¼ˆè·å–å¾®åšæ–‡æ¡ˆï¼‰\n",
    "print(\"\\nã€åŠ è½½çƒ­é—¨å¾®åšæ•°æ®ã€‘\")\n",
    "weibo_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åš_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"çƒ­é—¨å¾®åš: {len(weibo_df):,} æ¡\")\n",
    "print(f\"çƒ­é—¨å¾®åšåˆ—: {list(weibo_df.columns)}\")\n",
    "\n",
    "# åˆ›å»º weibo_url -> weibo_content æ˜ å°„\n",
    "weibo_content_map = dict(zip(weibo_df['weibo_url'], weibo_df['weibo_content']))\n",
    "print(f\"å¾®åšæ–‡æ¡ˆæ˜ å°„æ•°: {len(weibo_content_map):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€åˆ›å»ºè¯„è®ºæ–‡æ¡ˆæ˜ å°„ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯„è®ºæ–‡æ¡ˆæ˜ å°„æ•°: 273,937\n"
     ]
    }
   ],
   "source": [
    "# 3. åˆ›å»ºè¯„è®ºID -> è¯„è®ºå†…å®¹æ˜ å°„ï¼ˆç”¨äºè·å–æ ¹è¯„è®º/çˆ¶è¯„è®ºæ–‡æ¡ˆï¼‰\n",
    "print(\"\\nã€åˆ›å»ºè¯„è®ºæ–‡æ¡ˆæ˜ å°„ã€‘\")\n",
    "\n",
    "# æ ‡å‡†åŒ–è¯„è®ºIDï¼ˆç§»é™¤.0åç¼€ï¼‰\n",
    "def normalize_id(id_val):\n",
    "    if pd.isna(id_val):\n",
    "        return None\n",
    "    return str(int(float(id_val))) if not pd.isna(id_val) else None\n",
    "\n",
    "comments_df['è¯„è®ºID_str'] = comments_df['è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['æ ¹è¯„è®ºID_str'] = comments_df['æ ¹è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['çˆ¶è¯„è®ºID_str'] = comments_df['çˆ¶è¯„è®ºID'].apply(normalize_id)\n",
    "\n",
    "# åˆ›å»ºè¯„è®ºID -> è¯„è®ºå†…å®¹æ˜ å°„\n",
    "comment_content_map = dict(zip(comments_df['è¯„è®ºID_str'], comments_df['è¯„è®ºå†…å®¹']))\n",
    "print(f\"è¯„è®ºæ–‡æ¡ˆæ˜ å°„æ•°: {len(comment_content_map):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€æ„å»ºç‰¹å¾è¡¨ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¾®åšæ–‡æ¡ˆç¼ºå¤±: 35\n",
      "æ ¹è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: 156,171 (ä¸€çº§è¯„è®ºæ— æ ¹è¯„è®º)\n",
      "çˆ¶è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: 1,500\n"
     ]
    }
   ],
   "source": [
    "# 4. æ„å»ºç‰¹å¾è¡¨\n",
    "print(\"\\nã€æ„å»ºç‰¹å¾è¡¨ã€‘\")\n",
    "\n",
    "# æ·»åŠ å¾®åšæ–‡æ¡ˆ\n",
    "comments_df['å¾®åšæ–‡æ¡ˆ'] = comments_df['åŸæ–‡é“¾æ¥'].map(weibo_content_map)\n",
    "\n",
    "# æ·»åŠ æ ¹è¯„è®ºæ–‡æ¡ˆï¼ˆä¸€çº§è¯„è®ºçš„æ ¹è¯„è®ºä¸ºç©ºï¼‰\n",
    "comments_df['æ ¹è¯„è®ºæ–‡æ¡ˆ'] = comments_df['æ ¹è¯„è®ºID_str'].map(comment_content_map)\n",
    "\n",
    "# æ·»åŠ çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "# å¯¹äºä¸€çº§è¯„è®ºï¼Œçˆ¶è¯„è®ºIDå®é™…ä¸Šæ˜¯å¾®åšä½œè€…IDï¼Œä¸æ˜¯è¯„è®ºID\n",
    "# éœ€è¦åˆ¤æ–­ï¼šå¦‚æœæ˜¯ä¸€çº§è¯„è®ºï¼Œçˆ¶è¯„è®ºæ–‡æ¡ˆåº”è¯¥æ˜¯å¾®åšæ–‡æ¡ˆï¼›å¦åˆ™æ˜¯çˆ¶è¯„è®ºå†…å®¹\n",
    "def get_parent_content(row):\n",
    "    if row['æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º']:\n",
    "        return row['å¾®åšæ–‡æ¡ˆ']  # ä¸€çº§è¯„è®ºçš„çˆ¶å†…å®¹æ˜¯å¾®åš\n",
    "    else:\n",
    "        return comment_content_map.get(row['çˆ¶è¯„è®ºID_str'], None)\n",
    "\n",
    "comments_df['çˆ¶è¯„è®ºæ–‡æ¡ˆ'] = comments_df.apply(get_parent_content, axis=1)\n",
    "\n",
    "# æŸ¥çœ‹ç¼ºå¤±æƒ…å†µ\n",
    "print(f\"å¾®åšæ–‡æ¡ˆç¼ºå¤±: {comments_df['å¾®åšæ–‡æ¡ˆ'].isna().sum():,}\")\n",
    "print(f\"æ ¹è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: {comments_df['æ ¹è¯„è®ºæ–‡æ¡ˆ'].isna().sum():,} (ä¸€çº§è¯„è®ºæ— æ ¹è¯„è®º)\")\n",
    "print(f\"çˆ¶è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: {comments_df['çˆ¶è¯„è®ºæ–‡æ¡ˆ'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€é€‰æ‹©ç‰¹å¾åˆ—ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾è¡¨å¤§å°: 273,937 æ¡\n",
      "ç‰¹å¾åˆ—: ['è¯„è®ºæ–‡æ¡ˆ', 'å¾®åšæ–‡æ¡ˆ', 'æ ¹è¯„è®ºæ–‡æ¡ˆ', 'çˆ¶è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´', 'ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°', 'ç”¨æˆ·æ˜¯å¦è®¤è¯', 'æ˜¯å¦ä¸€çº§è¯„è®º', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°']\n",
      "\n",
      "ç‰¹å¾æ•°æ®ç¤ºä¾‹:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>è¯„è®ºæ–‡æ¡ˆ</th>\n",
       "      <th>å¾®åšæ–‡æ¡ˆ</th>\n",
       "      <th>æ ¹è¯„è®ºæ–‡æ¡ˆ</th>\n",
       "      <th>çˆ¶è¯„è®ºæ–‡æ¡ˆ</th>\n",
       "      <th>å‘å¸ƒæ—¶é—´</th>\n",
       "      <th>ç”¨æˆ·æ€»è½¬å‘æ•°</th>\n",
       "      <th>ç”¨æˆ·æ€»è¯„è®ºæ•°</th>\n",
       "      <th>ç”¨æˆ·æ€»ç‚¹èµæ•°</th>\n",
       "      <th>ç”¨æˆ·æ˜¯å¦è®¤è¯</th>\n",
       "      <th>æ˜¯å¦ä¸€çº§è¯„è®º</th>\n",
       "      <th>å­è¯„è®ºæ•°</th>\n",
       "      <th>ç‚¹èµæ•°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...</td>\n",
       "      <td>ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...</td>\n",
       "      <td>2025-03-27 18:26:25</td>\n",
       "      <td>610</td>\n",
       "      <td>25928</td>\n",
       "      <td>40859</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¯¹å¯¹å¯¹å•Š</td>\n",
       "      <td>ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...</td>\n",
       "      <td>éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...</td>\n",
       "      <td>éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...</td>\n",
       "      <td>2025-03-28 07:21:20</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>åŠ æ²¹åŠ æ²¹åŠ æ²¹</td>\n",
       "      <td>ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...</td>\n",
       "      <td>éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-27 18:28:55</td>\n",
       "      <td>610</td>\n",
       "      <td>25928</td>\n",
       "      <td>40859</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                è¯„è®ºæ–‡æ¡ˆ  \\\n",
       "0  éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...   \n",
       "1                                               å¯¹å¯¹å¯¹å•Š   \n",
       "2                                             åŠ æ²¹åŠ æ²¹åŠ æ²¹   \n",
       "\n",
       "                                                å¾®åšæ–‡æ¡ˆ  \\\n",
       "0  ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...   \n",
       "1  ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...   \n",
       "2  ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...   \n",
       "\n",
       "                                               æ ¹è¯„è®ºæ–‡æ¡ˆ  \\\n",
       "0                                                NaN   \n",
       "1  éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...   \n",
       "2  éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...   \n",
       "\n",
       "                                               çˆ¶è¯„è®ºæ–‡æ¡ˆ                 å‘å¸ƒæ—¶é—´  \\\n",
       "0  ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...  2025-03-27 18:26:25   \n",
       "1  éå¸¸å¥½éå¸¸å¥½ï¼Œå¥½äº§å“åº”å½“åƒå°ç±³æ±½è½¦ä¸€æ ·ä¼šè‡ªåŠ¨å®£ä¼ [é¼“æŒ][é¼“æŒ][é¼“æŒ][æ‰“call][æ‰“c...  2025-03-28 07:21:20   \n",
       "2                                                NaN  2025-03-27 18:28:55   \n",
       "\n",
       "   ç”¨æˆ·æ€»è½¬å‘æ•°  ç”¨æˆ·æ€»è¯„è®ºæ•°  ç”¨æˆ·æ€»ç‚¹èµæ•°  ç”¨æˆ·æ˜¯å¦è®¤è¯  æ˜¯å¦ä¸€çº§è¯„è®º  å­è¯„è®ºæ•°    ç‚¹èµæ•°  \n",
       "0     610   25928   40859    True    True     3  127.0  \n",
       "1      19      28      35   False   False     0    0.0  \n",
       "2     610   25928   40859    True   False     0    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. é€‰æ‹©å¹¶é‡å‘½åç‰¹å¾åˆ—\n",
    "print(\"\\nã€é€‰æ‹©ç‰¹å¾åˆ—ã€‘\")\n",
    "\n",
    "# å¤„ç†ç”¨æˆ·ç»Ÿè®¡æ•°æ®ï¼ˆå¯èƒ½æœ‰é€—å·ï¼‰\n",
    "def clean_number(x):\n",
    "    if isinstance(x, str):\n",
    "        return int(x.replace(',', ''))\n",
    "    return int(x) if not pd.isna(x) else 0\n",
    "\n",
    "comments_df['ç”¨æˆ·æ€»è½¬å‘æ•°_clean'] = comments_df['ç”¨æˆ·æ€»è½¬å‘æ•°'].apply(clean_number)\n",
    "comments_df['ç”¨æˆ·æ€»è¯„è®ºæ•°_clean'] = comments_df['ç”¨æˆ·æ€»è¯„è®ºæ•°'].apply(clean_number)\n",
    "comments_df['ç”¨æˆ·æ€»ç‚¹èµæ•°_clean'] = comments_df['ç”¨æˆ·æ€»ç‚¹èµæ•°'].apply(clean_number)\n",
    "\n",
    "# é€‰æ‹©ç‰¹å¾\n",
    "feature_df = comments_df[[\n",
    "    # è¯„è®ºæœ¬èº«æ–‡æ¡ˆ\n",
    "    'è¯„è®ºå†…å®¹',\n",
    "    # å¾®åš/æ ¹è¯„è®º/çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "    'å¾®åšæ–‡æ¡ˆ',\n",
    "    'æ ¹è¯„è®ºæ–‡æ¡ˆ',\n",
    "    'çˆ¶è¯„è®ºæ–‡æ¡ˆ',\n",
    "    # æ—¶é—´\n",
    "    'å‘å¸ƒæ—¶é—´',\n",
    "    # ä½œè€…ç»Ÿè®¡\n",
    "    'ç”¨æˆ·æ€»è½¬å‘æ•°_clean',\n",
    "    'ç”¨æˆ·æ€»è¯„è®ºæ•°_clean', \n",
    "    'ç”¨æˆ·æ€»ç‚¹èµæ•°_clean',\n",
    "    # ç”¨æˆ·æ˜¯å¦è®¤è¯\n",
    "    'ç”¨æˆ·è®¤è¯',\n",
    "    # æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º\n",
    "    'æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º',\n",
    "    # è¯„è®ºæœ¬èº«æŒ‡æ ‡ï¼ˆè¯„è®ºæ²¡æœ‰è½¬å‘æ•°ï¼Œåªæœ‰å­è¯„è®ºæ•°å’Œç‚¹èµæ•°ï¼‰\n",
    "    'å­è¯„è®ºæ•°',\n",
    "    'ç‚¹èµæ•°'\n",
    "]].copy()\n",
    "\n",
    "# é‡å‘½ååˆ—\n",
    "feature_df.columns = [\n",
    "    'è¯„è®ºæ–‡æ¡ˆ',\n",
    "    'å¾®åšæ–‡æ¡ˆ',\n",
    "    'æ ¹è¯„è®ºæ–‡æ¡ˆ',\n",
    "    'çˆ¶è¯„è®ºæ–‡æ¡ˆ',\n",
    "    'å‘å¸ƒæ—¶é—´',\n",
    "    'ç”¨æˆ·æ€»è½¬å‘æ•°',\n",
    "    'ç”¨æˆ·æ€»è¯„è®ºæ•°',\n",
    "    'ç”¨æˆ·æ€»ç‚¹èµæ•°',\n",
    "    'ç”¨æˆ·æ˜¯å¦è®¤è¯',\n",
    "    'æ˜¯å¦ä¸€çº§è¯„è®º',\n",
    "    'å­è¯„è®ºæ•°',\n",
    "    'ç‚¹èµæ•°'\n",
    "]\n",
    "\n",
    "print(f\"ç‰¹å¾è¡¨å¤§å°: {len(feature_df):,} æ¡\")\n",
    "print(f\"ç‰¹å¾åˆ—: {list(feature_df.columns)}\")\n",
    "print(f\"\\nç‰¹å¾æ•°æ®ç¤ºä¾‹:\")\n",
    "feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦–æ¬¡å‡ºç°çš„è¯„è®º: 246,090\n",
      "é‡å¤å‡ºç°çš„è¯„è®º: 25,362\n",
      "\n",
      "ç›®æ ‡éªŒè¯é›†å¤§å°: 27,393 (æ€»é‡çš„10%)\n"
     ]
    }
   ],
   "source": [
    "# 6. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "# è§„åˆ™ï¼šè¯„è®ºæ–‡æ¡ˆé‡å¤çš„æ•°æ®ä¸­ï¼Œæ—¶é—´ä¸Šç¬¬ä¸€æ¬¡å‡ºç°çš„å¿…é¡»æ”¾åœ¨è®­ç»ƒé›†\n",
    "print(\"\\nã€åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‘\")\n",
    "\n",
    "# è½¬æ¢æ—¶é—´åˆ—\n",
    "feature_df['å‘å¸ƒæ—¶é—´'] = pd.to_datetime(feature_df['å‘å¸ƒæ—¶é—´'])\n",
    "\n",
    "# æŒ‰è¯„è®ºæ–‡æ¡ˆå’Œæ—¶é—´æ’åº\n",
    "feature_df = feature_df.sort_values(['è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´']).reset_index(drop=True)\n",
    "\n",
    "# æ ‡è®°æ¯ä¸ªè¯„è®ºæ–‡æ¡ˆç»„å†…çš„é¡ºåº\n",
    "feature_df['æ–‡æ¡ˆé¡ºåº'] = feature_df.groupby('è¯„è®ºæ–‡æ¡ˆ').cumcount()\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡å‡ºç°çš„ï¼ˆé¡ºåº=0ï¼‰å¿…é¡»æ”¾å…¥è®­ç»ƒé›†\n",
    "first_occurrence = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] == 0].copy()\n",
    "later_occurrence = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] > 0].copy()\n",
    "\n",
    "print(f\"é¦–æ¬¡å‡ºç°çš„è¯„è®º: {len(first_occurrence):,}\")\n",
    "print(f\"é‡å¤å‡ºç°çš„è¯„è®º: {len(later_occurrence):,}\")\n",
    "\n",
    "# è®¡ç®—éœ€è¦çš„éªŒè¯é›†å¤§å°ï¼ˆæ€»é‡çš„10%ï¼‰\n",
    "total_size = len(feature_df)\n",
    "val_size = int(total_size * 0.1)\n",
    "print(f\"\\nç›®æ ‡éªŒè¯é›†å¤§å°: {val_size:,} (æ€»é‡çš„10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ— é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: 240,467\n",
      "\n",
      "è®­ç»ƒé›†å¤§å°: 244,059\n",
      "éªŒè¯é›†å¤§å°: 27,393\n",
      "æ¯”ä¾‹: 89.1% : 10.0%\n"
     ]
    }
   ],
   "source": [
    "# 7. åˆ†é…æ•°æ®åˆ°è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç­–ç•¥ï¼š\n",
    "# 1. é¦–æ¬¡å‡ºç°çš„è¯„è®ºå¿…é¡»æ”¾è®­ç»ƒé›†\n",
    "# 2. ä»é‡å¤å‡ºç°çš„è¯„è®ºä¸­æŠ½å–ä¸€éƒ¨åˆ†æ”¾éªŒè¯é›†\n",
    "# 3. å¦‚æœé‡å¤è¯„è®ºä¸å¤Ÿï¼Œä»é¦–æ¬¡å‡ºç°ä¸­æŠ½å–ï¼ˆä½†è¦ä¿è¯è¯¥æ–‡æ¡ˆçš„å…¶ä»–é‡å¤ä¹Ÿéƒ½åœ¨è®­ç»ƒé›†ï¼‰\n",
    "\n",
    "# é‡å¤è¯„è®ºæ•°é‡\n",
    "later_count = len(later_occurrence)\n",
    "\n",
    "if later_count >= val_size:\n",
    "    # é‡å¤è¯„è®ºè¶³å¤Ÿï¼Œç›´æ¥ä»ä¸­æŠ½å–\n",
    "    val_indices = np.random.choice(later_occurrence.index, size=val_size, replace=False)\n",
    "    val_df = later_occurrence.loc[val_indices]\n",
    "    train_df = pd.concat([first_occurrence, later_occurrence.drop(val_indices)])\n",
    "else:\n",
    "    # é‡å¤è¯„è®ºä¸å¤Ÿï¼Œå…¨éƒ¨æ”¾éªŒè¯é›†ï¼Œå†ä»é¦–æ¬¡å‡ºç°ä¸­è¡¥å……\n",
    "    # ä½†è¦ç¡®ä¿ï¼šå¦‚æœæŸä¸ªæ–‡æ¡ˆçš„é¦–æ¬¡å‡ºç°æ”¾å…¥éªŒè¯é›†ï¼Œè¯¥æ–‡æ¡ˆä¸èƒ½æœ‰é‡å¤å‡ºç°\n",
    "    need_more = val_size - later_count\n",
    "    \n",
    "    # æ‰¾å‡ºæ²¡æœ‰é‡å¤çš„é¦–æ¬¡å‡ºç°è¯„è®ºï¼ˆå¯ä»¥å®‰å…¨æ”¾å…¥éªŒè¯é›†ï¼‰\n",
    "    unique_contents = first_occurrence[~first_occurrence['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occurrence['è¯„è®ºæ–‡æ¡ˆ'])]\n",
    "    print(f\"æ— é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: {len(unique_contents):,}\")\n",
    "    \n",
    "    if len(unique_contents) >= need_more:\n",
    "        # ä»æ— é‡å¤è¯„è®ºä¸­æŠ½å–\n",
    "        extra_val_indices = np.random.choice(unique_contents.index, size=need_more, replace=False)\n",
    "        val_df = pd.concat([later_occurrence, unique_contents.loc[extra_val_indices]])\n",
    "        train_df = first_occurrence.drop(extra_val_indices)\n",
    "    else:\n",
    "        # æ— é‡å¤è¯„è®ºä¹Ÿä¸å¤Ÿï¼Œå…¨éƒ¨ä½¿ç”¨\n",
    "        val_df = pd.concat([later_occurrence, unique_contents])\n",
    "        train_df = first_occurrence.drop(unique_contents.index)\n",
    "        print(f\"è­¦å‘Š: éªŒè¯é›†å¤§å° {len(val_df)} å°äºç›®æ ‡ {val_size}\")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒé›†å¤§å°: {len(train_df):,}\")\n",
    "print(f\"éªŒè¯é›†å¤§å°: {len(val_df):,}\")\n",
    "print(f\"æ¯”ä¾‹: {len(train_df)/len(feature_df)*100:.1f}% : {len(val_df)/len(feature_df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€éªŒè¯åˆ’åˆ†æ­£ç¡®æ€§ã€‘\n",
      "æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: 5,623\n",
      "å…¶ä¸­åœ¨è®­ç»ƒé›†çš„: 5,623\n",
      "å…¶ä¸­åœ¨éªŒè¯é›†çš„: 0\n",
      "âœ“ éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰é‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°éƒ½åœ¨è®­ç»ƒé›†ä¸­\n"
     ]
    }
   ],
   "source": [
    "# 8. éªŒè¯åˆ’åˆ†çš„æ­£ç¡®æ€§\n",
    "print(\"\\nã€éªŒè¯åˆ’åˆ†æ­£ç¡®æ€§ã€‘\")\n",
    "\n",
    "# æ£€æŸ¥ï¼šé‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°æ˜¯å¦éƒ½åœ¨è®­ç»ƒé›†ä¸­\n",
    "duplicated_contents = later_occurrence['è¯„è®ºæ–‡æ¡ˆ'].unique()\n",
    "first_of_duplicated = first_occurrence[first_occurrence['è¯„è®ºæ–‡æ¡ˆ'].isin(duplicated_contents)]\n",
    "\n",
    "in_train = first_of_duplicated.index.isin(train_df.index)\n",
    "print(f\"æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: {len(first_of_duplicated):,}\")\n",
    "print(f\"å…¶ä¸­åœ¨è®­ç»ƒé›†çš„: {in_train.sum():,}\")\n",
    "print(f\"å…¶ä¸­åœ¨éªŒè¯é›†çš„: {(~in_train).sum():,}\")\n",
    "\n",
    "if (~in_train).sum() == 0:\n",
    "    print(\"âœ“ éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰é‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°éƒ½åœ¨è®­ç»ƒé›†ä¸­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€ä¿å­˜æ•°æ®ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†å·²ä¿å­˜: D:/010_CodePrograms/L/LLM_su7/results/train.csv\n",
      "éªŒè¯é›†å·²ä¿å­˜: D:/010_CodePrograms/L/LLM_su7/results/val.csv\n",
      "\n",
      "ã€æœ€ç»ˆæ•°æ®ç»Ÿè®¡ã€‘\n",
      "è®­ç»ƒé›†: 244,059 æ¡ (89.1%)\n",
      "éªŒè¯é›†: 27,393 æ¡ (10.0%)\n",
      "\n",
      "ç‰¹å¾åˆ—: ['è¯„è®ºæ–‡æ¡ˆ', 'å¾®åšæ–‡æ¡ˆ', 'æ ¹è¯„è®ºæ–‡æ¡ˆ', 'çˆ¶è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´', 'ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°', 'ç”¨æˆ·æ˜¯å¦è®¤è¯', 'æ˜¯å¦ä¸€çº§è¯„è®º', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°']\n"
     ]
    }
   ],
   "source": [
    "# 9. ä¿å­˜è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "print(\"\\nã€ä¿å­˜æ•°æ®ã€‘\")\n",
    "\n",
    "# åˆ é™¤è¾…åŠ©åˆ—\n",
    "train_df = train_df.drop(columns=['æ–‡æ¡ˆé¡ºåº'])\n",
    "val_df = val_df.drop(columns=['æ–‡æ¡ˆé¡ºåº'])\n",
    "\n",
    "# é‡ç½®ç´¢å¼•\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "# ä¿å­˜\n",
    "train_path = f'{RESULTS_DIR}/train.csv'\n",
    "val_path = f'{RESULTS_DIR}/val.csv'\n",
    "\n",
    "train_df.to_csv(train_path, index=False, encoding='utf-8-sig')\n",
    "val_df.to_csv(val_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å·²ä¿å­˜: {train_path}\")\n",
    "print(f\"éªŒè¯é›†å·²ä¿å­˜: {val_path}\")\n",
    "\n",
    "print(f\"\\nã€æœ€ç»ˆæ•°æ®ç»Ÿè®¡ã€‘\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_df):,} æ¡ ({len(train_df)/len(feature_df)*100:.1f}%)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_df):,} æ¡ ({len(val_df)/len(feature_df)*100:.1f}%)\")\n",
    "print(f\"\\nç‰¹å¾åˆ—: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€æ•°æ®é›†æ¦‚è§ˆã€‘\n",
      "============================================================\n",
      "\n",
      "--- è®­ç»ƒé›† ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244059 entries, 0 to 244058\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   è¯„è®ºæ–‡æ¡ˆ    244059 non-null  object        \n",
      " 1   å¾®åšæ–‡æ¡ˆ    244026 non-null  object        \n",
      " 2   æ ¹è¯„è®ºæ–‡æ¡ˆ   108322 non-null  object        \n",
      " 3   çˆ¶è¯„è®ºæ–‡æ¡ˆ   242853 non-null  object        \n",
      " 4   å‘å¸ƒæ—¶é—´    244059 non-null  datetime64[ns]\n",
      " 5   ç”¨æˆ·æ€»è½¬å‘æ•°  244059 non-null  int64         \n",
      " 6   ç”¨æˆ·æ€»è¯„è®ºæ•°  244059 non-null  int64         \n",
      " 7   ç”¨æˆ·æ€»ç‚¹èµæ•°  244059 non-null  int64         \n",
      " 8   ç”¨æˆ·æ˜¯å¦è®¤è¯  244059 non-null  bool          \n",
      " 9   æ˜¯å¦ä¸€çº§è¯„è®º  244059 non-null  bool          \n",
      " 10  å­è¯„è®ºæ•°    244059 non-null  int64         \n",
      " 11  ç‚¹èµæ•°     180854 non-null  float64       \n",
      "dtypes: bool(2), datetime64[ns](1), float64(1), int64(4), object(4)\n",
      "memory usage: 19.1+ MB\n",
      "None\n",
      "\n",
      "ç¼ºå¤±å€¼ç»Ÿè®¡:\n",
      "è¯„è®ºæ–‡æ¡ˆ           0\n",
      "å¾®åšæ–‡æ¡ˆ          33\n",
      "æ ¹è¯„è®ºæ–‡æ¡ˆ     135737\n",
      "çˆ¶è¯„è®ºæ–‡æ¡ˆ       1206\n",
      "å‘å¸ƒæ—¶é—´           0\n",
      "ç”¨æˆ·æ€»è½¬å‘æ•°         0\n",
      "ç”¨æˆ·æ€»è¯„è®ºæ•°         0\n",
      "ç”¨æˆ·æ€»ç‚¹èµæ•°         0\n",
      "ç”¨æˆ·æ˜¯å¦è®¤è¯         0\n",
      "æ˜¯å¦ä¸€çº§è¯„è®º         0\n",
      "å­è¯„è®ºæ•°           0\n",
      "ç‚¹èµæ•°        63205\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- éªŒè¯é›† ---\n",
      "ç¼ºå¤±å€¼ç»Ÿè®¡:\n",
      "è¯„è®ºæ–‡æ¡ˆ          0\n",
      "å¾®åšæ–‡æ¡ˆ          1\n",
      "æ ¹è¯„è®ºæ–‡æ¡ˆ     20434\n",
      "çˆ¶è¯„è®ºæ–‡æ¡ˆ       110\n",
      "å‘å¸ƒæ—¶é—´          0\n",
      "ç”¨æˆ·æ€»è½¬å‘æ•°        0\n",
      "ç”¨æˆ·æ€»è¯„è®ºæ•°        0\n",
      "ç”¨æˆ·æ€»ç‚¹èµæ•°        0\n",
      "ç”¨æˆ·æ˜¯å¦è®¤è¯        0\n",
      "æ˜¯å¦ä¸€çº§è¯„è®º        0\n",
      "å­è¯„è®ºæ•°          0\n",
      "ç‚¹èµæ•°        6263\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- æ•°å€¼ç‰¹å¾åˆ†å¸ƒ ---\n",
      "è®­ç»ƒé›†:\n",
      "             ç”¨æˆ·æ€»è½¬å‘æ•°        ç”¨æˆ·æ€»è¯„è®ºæ•°        ç”¨æˆ·æ€»ç‚¹èµæ•°           å­è¯„è®ºæ•°            ç‚¹èµæ•°\n",
      "count  2.440590e+05  2.440590e+05  2.440590e+05  244059.000000  180854.000000\n",
      "mean   6.296865e+04  7.582426e+04  2.146437e+05       0.848315       2.751463\n",
      "std    7.556226e+05  8.434799e+05  2.086540e+06      13.478123     112.104086\n",
      "min   -1.000000e+00 -1.000000e+00 -2.000000e+00       0.000000       0.000000\n",
      "25%    0.000000e+00  1.000000e+00  6.000000e+00       0.000000       0.000000\n",
      "50%    3.000000e+00  3.000000e+01  6.100000e+01       0.000000       0.000000\n",
      "75%    6.200000e+01  3.050000e+02  3.740000e+02       0.000000       0.000000\n",
      "max    1.038909e+08  2.956738e+07  1.808344e+08    2606.000000   29471.000000\n"
     ]
    }
   ],
   "source": [
    "# 10. æ•°æ®æ¦‚è§ˆ\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€æ•°æ®é›†æ¦‚è§ˆã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- è®­ç»ƒé›† ---\")\n",
    "print(train_df.info())\n",
    "print(f\"\\nç¼ºå¤±å€¼ç»Ÿè®¡:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\n\\n--- éªŒè¯é›† ---\")\n",
    "print(f\"ç¼ºå¤±å€¼ç»Ÿè®¡:\")\n",
    "print(val_df.isnull().sum())\n",
    "\n",
    "print(\"\\n\\n--- æ•°å€¼ç‰¹å¾åˆ†å¸ƒ ---\")\n",
    "print(\"è®­ç»ƒé›†:\")\n",
    "print(train_df[['ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€å®Œæˆã€‘\n",
      "============================================================\n",
      "\n",
      "å·²åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†:\n",
      "â€¢ results/train.csv: 244,059 æ¡ (89.1%)\n",
      "â€¢ results/val.csv: 27,393 æ¡ (10.0%)\n",
      "\n",
      "ç‰¹å¾è¯´æ˜:\n",
      "1. è¯„è®ºæ–‡æ¡ˆ: è¯„è®ºæœ¬èº«çš„æ–‡æ¡ˆå†…å®¹\n",
      "2. å¾®åšæ–‡æ¡ˆ: è¯¥è¯„è®ºæ‰€å±å¾®åšçš„å†…å®¹\n",
      "3. æ ¹è¯„è®ºæ–‡æ¡ˆ: æ ¹è¯„è®ºå†…å®¹ï¼ˆä¸€çº§è¯„è®ºä¸ºç©ºï¼‰\n",
      "4. çˆ¶è¯„è®ºæ–‡æ¡ˆ: çˆ¶è¯„è®º/å¾®åšå†…å®¹\n",
      "5. å‘å¸ƒæ—¶é—´: è¯„è®ºå‘å¸ƒæ—¶é—´\n",
      "6. ç”¨æˆ·æ€»è½¬å‘æ•°: è¯„è®ºä½œè€…çš„å†å²è½¬å‘æ€»æ•°\n",
      "7. ç”¨æˆ·æ€»è¯„è®ºæ•°: è¯„è®ºä½œè€…çš„å†å²è¯„è®ºæ€»æ•°\n",
      "8. ç”¨æˆ·æ€»ç‚¹èµæ•°: è¯„è®ºä½œè€…çš„å†å²ç‚¹èµæ€»æ•°\n",
      "9. ç”¨æˆ·æ˜¯å¦è®¤è¯: è¯„è®ºä½œè€…æ˜¯å¦è®¤è¯ç”¨æˆ·\n",
      "10. æ˜¯å¦ä¸€çº§è¯„è®º: æ˜¯å¦ä¸ºä¸€çº§è¯„è®ºï¼ˆç›´æ¥è¯„è®ºå¾®åšï¼‰\n",
      "11. å­è¯„è®ºæ•°: è¯¥è¯„è®ºè·å¾—çš„å›å¤æ•°\n",
      "12. ç‚¹èµæ•°: è¯¥è¯„è®ºè·å¾—çš„ç‚¹èµæ•°\n",
      "\n",
      "åˆ’åˆ†è§„åˆ™:\n",
      "â€¢ è¯„è®ºæ–‡æ¡ˆé‡å¤çš„æ•°æ®ä¸­ï¼Œæ—¶é—´ä¸Šé¦–æ¬¡å‡ºç°çš„å¿…é¡»åœ¨è®­ç»ƒé›†\n",
      "â€¢ è®­ç»ƒé›†:éªŒè¯é›† â‰ˆ 9:1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ã€å®Œæˆã€‘\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "å·²åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†:\n",
    "â€¢ results/train.csv: {len(train_df):,} æ¡ (89.1%)\n",
    "â€¢ results/val.csv: {len(val_df):,} æ¡ (10.0%)\n",
    "\n",
    "ç‰¹å¾è¯´æ˜:\n",
    "1. è¯„è®ºæ–‡æ¡ˆ: è¯„è®ºæœ¬èº«çš„æ–‡æ¡ˆå†…å®¹\n",
    "2. å¾®åšæ–‡æ¡ˆ: è¯¥è¯„è®ºæ‰€å±å¾®åšçš„å†…å®¹\n",
    "3. æ ¹è¯„è®ºæ–‡æ¡ˆ: æ ¹è¯„è®ºå†…å®¹ï¼ˆä¸€çº§è¯„è®ºä¸ºç©ºï¼‰\n",
    "4. çˆ¶è¯„è®ºæ–‡æ¡ˆ: çˆ¶è¯„è®º/å¾®åšå†…å®¹\n",
    "5. å‘å¸ƒæ—¶é—´: è¯„è®ºå‘å¸ƒæ—¶é—´\n",
    "6. ç”¨æˆ·æ€»è½¬å‘æ•°: è¯„è®ºä½œè€…çš„å†å²è½¬å‘æ€»æ•°\n",
    "7. ç”¨æˆ·æ€»è¯„è®ºæ•°: è¯„è®ºä½œè€…çš„å†å²è¯„è®ºæ€»æ•°\n",
    "8. ç”¨æˆ·æ€»ç‚¹èµæ•°: è¯„è®ºä½œè€…çš„å†å²ç‚¹èµæ€»æ•°\n",
    "9. ç”¨æˆ·æ˜¯å¦è®¤è¯: è¯„è®ºä½œè€…æ˜¯å¦è®¤è¯ç”¨æˆ·\n",
    "10. æ˜¯å¦ä¸€çº§è¯„è®º: æ˜¯å¦ä¸ºä¸€çº§è¯„è®ºï¼ˆç›´æ¥è¯„è®ºå¾®åšï¼‰\n",
    "11. å­è¯„è®ºæ•°: è¯¥è¯„è®ºè·å¾—çš„å›å¤æ•°\n",
    "12. ç‚¹èµæ•°: è¯¥è¯„è®ºè·å¾—çš„ç‚¹èµæ•°\n",
    "\n",
    "åˆ’åˆ†è§„åˆ™:\n",
    "â€¢ è¯„è®ºæ–‡æ¡ˆé‡å¤çš„æ•°æ®ä¸­ï¼Œæ—¶é—´ä¸Šé¦–æ¬¡å‡ºç°çš„å¿…é¡»åœ¨è®­ç»ƒé›†\n",
    "â€¢ è®­ç»ƒé›†:éªŒè¯é›† â‰ˆ 9:1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€é‡æ–°åˆ’åˆ†ï¼š8:1:1ã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€»æ•°æ®é‡: 273,937\n",
      "ç›®æ ‡è®­ç»ƒé›†: 219,151 (80%)\n",
      "ç›®æ ‡éªŒè¯é›†: 27,393 (10%)\n",
      "ç›®æ ‡æµ‹è¯•é›†: 27,393 (10%)\n",
      "\n",
      "é¦–æ¬¡å‡ºç°çš„è¯„è®º: 246,090\n",
      "é‡å¤å‡ºç°çš„è¯„è®º: 25,362\n"
     ]
    }
   ],
   "source": [
    "# 11. é‡æ–°åˆ’åˆ†ï¼šè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›† = 8:1:1\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€é‡æ–°åˆ’åˆ†ï¼š8:1:1ã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# é‡æ–°åŠ è½½ç‰¹å¾æ•°æ®\n",
    "feature_df = feature_df.sort_values(['è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´']).reset_index(drop=True)\n",
    "feature_df['æ–‡æ¡ˆé¡ºåº'] = feature_df.groupby('è¯„è®ºæ–‡æ¡ˆ').cumcount()\n",
    "\n",
    "first_occurrence = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] == 0].copy()\n",
    "later_occurrence = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] > 0].copy()\n",
    "\n",
    "total_size = len(feature_df)\n",
    "val_size = int(total_size * 0.1)  # 10%\n",
    "test_size = int(total_size * 0.1)  # 10%\n",
    "val_test_size = val_size + test_size  # 20%\n",
    "\n",
    "print(f\"æ€»æ•°æ®é‡: {total_size:,}\")\n",
    "print(f\"ç›®æ ‡è®­ç»ƒé›†: {total_size - val_test_size:,} (80%)\")\n",
    "print(f\"ç›®æ ‡éªŒè¯é›†: {val_size:,} (10%)\")\n",
    "print(f\"ç›®æ ‡æµ‹è¯•é›†: {test_size:,} (10%)\")\n",
    "print(f\"\\né¦–æ¬¡å‡ºç°çš„è¯„è®º: {len(first_occurrence):,}\")\n",
    "print(f\"é‡å¤å‡ºç°çš„è¯„è®º: {len(later_occurrence):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ— é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: 240,467\n",
      "å¯ç”¨äºéªŒè¯/æµ‹è¯•çš„æ•°æ®: 265,829\n",
      "\n",
      "è®­ç»ƒé›†: 216,666 (79.1%)\n",
      "éªŒè¯é›†: 27,393 (10.0%)\n",
      "æµ‹è¯•é›†: 27,393 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# 12. åˆ†é…æ•°æ®\n",
    "# è§„åˆ™ï¼šé‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°å¿…é¡»åœ¨è®­ç»ƒé›†\n",
    "\n",
    "later_count = len(later_occurrence)\n",
    "\n",
    "# æ‰¾å‡ºæ— é‡å¤çš„é¦–æ¬¡å‡ºç°è¯„è®º\n",
    "unique_contents = first_occurrence[~first_occurrence['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occurrence['è¯„è®ºæ–‡æ¡ˆ'])]\n",
    "print(f\"æ— é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: {len(unique_contents):,}\")\n",
    "\n",
    "# ä»é‡å¤è¯„è®ºå’Œæ— é‡å¤é¦–æ¬¡è¯„è®ºä¸­æŠ½å–éªŒè¯é›†å’Œæµ‹è¯•é›†\n",
    "available_for_val_test = pd.concat([later_occurrence, unique_contents])\n",
    "print(f\"å¯ç”¨äºéªŒè¯/æµ‹è¯•çš„æ•°æ®: {len(available_for_val_test):,}\")\n",
    "\n",
    "# éšæœºæ‰“ä¹±å¹¶åˆ†é…\n",
    "available_shuffled = available_for_val_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_df = available_shuffled.iloc[:val_size].copy()\n",
    "test_df = available_shuffled.iloc[val_size:val_size+test_size].copy()\n",
    "used_indices = set(val_df.index.tolist() + test_df.index.tolist())\n",
    "\n",
    "# å‰©ä½™çš„æ”¾å…¥è®­ç»ƒé›†\n",
    "train_from_available = available_shuffled.iloc[val_size+test_size:].copy()\n",
    "\n",
    "# åŠ ä¸Šæœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰\n",
    "first_with_dup = first_occurrence[first_occurrence['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occurrence['è¯„è®ºæ–‡æ¡ˆ'])]\n",
    "train_df = pd.concat([first_with_dup, train_from_available])\n",
    "\n",
    "print(f\"\\nè®­ç»ƒé›†: {len(train_df):,} ({len(train_df)/total_size*100:.1f}%)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_df):,} ({len(val_df)/total_size*100:.1f}%)\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_df):,} ({len(test_df)/total_size*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€éªŒè¯åˆ’åˆ†æ­£ç¡®æ€§ã€‘\n",
      "æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: 5,623\n",
      "å…¶ä¸­åœ¨è®­ç»ƒé›†çš„: 5,623\n",
      "âœ“ éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰é‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°éƒ½åœ¨è®­ç»ƒé›†ä¸­\n",
      "\n",
      "æ•°æ®æ€»é‡éªŒè¯: 271,452 = 273,937\n"
     ]
    }
   ],
   "source": [
    "# 13. éªŒè¯åˆ’åˆ†æ­£ç¡®æ€§\n",
    "print(\"\\nã€éªŒè¯åˆ’åˆ†æ­£ç¡®æ€§ã€‘\")\n",
    "\n",
    "# æ£€æŸ¥ï¼šé‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°æ˜¯å¦éƒ½åœ¨è®­ç»ƒé›†ä¸­\n",
    "duplicated_contents = later_occurrence['è¯„è®ºæ–‡æ¡ˆ'].unique()\n",
    "first_of_duplicated = first_occurrence[first_occurrence['è¯„è®ºæ–‡æ¡ˆ'].isin(duplicated_contents)]\n",
    "\n",
    "# è·å–åŸå§‹ç´¢å¼•\n",
    "train_original_idx = set(train_df.index if 'æ–‡æ¡ˆé¡ºåº' in train_df.columns else [])\n",
    "\n",
    "in_train = first_of_duplicated.index.isin(train_df.index)\n",
    "print(f\"æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºæ•°: {len(first_of_duplicated):,}\")\n",
    "print(f\"å…¶ä¸­åœ¨è®­ç»ƒé›†çš„: {in_train.sum():,}\")\n",
    "\n",
    "if in_train.sum() == len(first_of_duplicated):\n",
    "    print(\"âœ“ éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰é‡å¤è¯„è®ºçš„é¦–æ¬¡å‡ºç°éƒ½åœ¨è®­ç»ƒé›†ä¸­\")\n",
    "else:\n",
    "    print(\"âœ— éªŒè¯å¤±è´¥\")\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®æ— äº¤å‰\n",
    "train_comments = set(train_df['è¯„è®ºæ–‡æ¡ˆ'].tolist())\n",
    "val_comments = set(val_df['è¯„è®ºæ–‡æ¡ˆ'].tolist())\n",
    "test_comments = set(test_df['è¯„è®ºæ–‡æ¡ˆ'].tolist())\n",
    "\n",
    "print(f\"\\næ•°æ®æ€»é‡éªŒè¯: {len(train_df) + len(val_df) + len(test_df):,} = {total_size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ä¿®æ­£åˆ’åˆ†é€»è¾‘ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦–æ¬¡å‡ºç°ä¸”æœ‰é‡å¤ï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰: 5,623\n",
      "é¦–æ¬¡å‡ºç°ä¸”æ— é‡å¤ï¼ˆå¯åˆ†é…ï¼‰: 240,467\n",
      "é‡å¤å‡ºç°ï¼ˆå¯åˆ†é…ï¼‰: 25,362\n",
      "å¯åˆ†é…æ€»æ•°: 265,829\n",
      "\n",
      "æœ€ç»ˆåˆ’åˆ†:\n",
      "è®­ç»ƒé›†: 216,666 (79.1%)\n",
      "éªŒè¯é›†: 27,393 (10.0%)\n",
      "æµ‹è¯•é›†: 27,393 (10.0%)\n",
      "æ€»è®¡: 271,452 = 273,937\n"
     ]
    }
   ],
   "source": [
    "# 14. ä¿®æ­£åˆ’åˆ†é€»è¾‘\n",
    "print(\"ã€ä¿®æ­£åˆ’åˆ†é€»è¾‘ã€‘\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# é‡æ–°å¼€å§‹\n",
    "feature_df_clean = feature_df.copy()\n",
    "feature_df_clean = feature_df_clean.sort_values(['è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´']).reset_index(drop=True)\n",
    "feature_df_clean['æ–‡æ¡ˆé¡ºåº'] = feature_df_clean.groupby('è¯„è®ºæ–‡æ¡ˆ').cumcount()\n",
    "\n",
    "# åˆ†ç¦»é¦–æ¬¡å‡ºç°å’Œé‡å¤å‡ºç°\n",
    "first_occ = feature_df_clean[feature_df_clean['æ–‡æ¡ˆé¡ºåº'] == 0].copy()\n",
    "later_occ = feature_df_clean[feature_df_clean['æ–‡æ¡ˆé¡ºåº'] > 0].copy()\n",
    "\n",
    "# æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰\n",
    "has_dup_mask = first_occ['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occ['è¯„è®ºæ–‡æ¡ˆ'])\n",
    "first_with_dup = first_occ[has_dup_mask].copy()  # å¿…é¡»åœ¨è®­ç»ƒé›†\n",
    "first_no_dup = first_occ[~has_dup_mask].copy()   # å¯ä»¥åˆ†é…åˆ°ä»»æ„é›†åˆ\n",
    "\n",
    "print(f\"é¦–æ¬¡å‡ºç°ä¸”æœ‰é‡å¤ï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰: {len(first_with_dup):,}\")\n",
    "print(f\"é¦–æ¬¡å‡ºç°ä¸”æ— é‡å¤ï¼ˆå¯åˆ†é…ï¼‰: {len(first_no_dup):,}\")\n",
    "print(f\"é‡å¤å‡ºç°ï¼ˆå¯åˆ†é…ï¼‰: {len(later_occ):,}\")\n",
    "\n",
    "# å¯åˆ†é…çš„æ•°æ®\n",
    "available = pd.concat([first_no_dup, later_occ]).sample(frac=1, random_state=42)\n",
    "print(f\"å¯åˆ†é…æ€»æ•°: {len(available):,}\")\n",
    "\n",
    "# è®¡ç®—å„é›†åˆå¤§å°\n",
    "total = len(feature_df_clean)\n",
    "val_size = int(total * 0.1)\n",
    "test_size = int(total * 0.1)\n",
    "\n",
    "# åˆ†é…\n",
    "val_df = available.iloc[:val_size].copy()\n",
    "test_df = available.iloc[val_size:val_size+test_size].copy()\n",
    "train_from_available = available.iloc[val_size+test_size:].copy()\n",
    "train_df = pd.concat([first_with_dup, train_from_available])\n",
    "\n",
    "print(f\"\\næœ€ç»ˆåˆ’åˆ†:\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_df):,} ({len(train_df)/total*100:.1f}%)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_df):,} ({len(val_df)/total*100:.1f}%)\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_df):,} ({len(test_df)/total*100:.1f}%)\")\n",
    "print(f\"æ€»è®¡: {len(train_df)+len(val_df)+len(test_df):,} = {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€æ£€æŸ¥æ•°æ®å·®å¼‚ã€‘\n",
      "feature_df_clean æ€»æ•°: 273,937\n",
      "first_occ + later_occ: 271,452\n",
      "\n",
      "è¯„è®ºæ–‡æ¡ˆä¸ºç©º(NaN): 2,485\n",
      "è¯„è®ºæ–‡æ¡ˆä¸ºç©ºå­—ç¬¦ä¸²: 0\n",
      "\n",
      "ç©ºè¯„è®ºæ•°æ®é‡: 2,485\n",
      "è¿™äº›ç©ºè¯„è®ºä¼šè¢«groupbyåˆå¹¶ï¼Œå¯¼è‡´è®¡æ•°å·®å¼‚\n"
     ]
    }
   ],
   "source": [
    "# 15. æ£€æŸ¥æ•°æ®ç¼ºå¤±\n",
    "print(\"ã€æ£€æŸ¥æ•°æ®å·®å¼‚ã€‘\")\n",
    "print(f\"feature_df_clean æ€»æ•°: {len(feature_df_clean):,}\")\n",
    "print(f\"first_occ + later_occ: {len(first_occ) + len(later_occ):,}\")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰ç©ºè¯„è®ºæ–‡æ¡ˆ\n",
    "null_comments = feature_df_clean['è¯„è®ºæ–‡æ¡ˆ'].isna().sum()\n",
    "empty_comments = (feature_df_clean['è¯„è®ºæ–‡æ¡ˆ'] == '').sum()\n",
    "print(f\"\\nè¯„è®ºæ–‡æ¡ˆä¸ºç©º(NaN): {null_comments:,}\")\n",
    "print(f\"è¯„è®ºæ–‡æ¡ˆä¸ºç©ºå­—ç¬¦ä¸²: {empty_comments:,}\")\n",
    "\n",
    "# æ£€æŸ¥ç©ºè¯„è®ºçš„æƒ…å†µ\n",
    "if null_comments > 0 or empty_comments > 0:\n",
    "    empty_mask = feature_df_clean['è¯„è®ºæ–‡æ¡ˆ'].isna() | (feature_df_clean['è¯„è®ºæ–‡æ¡ˆ'] == '')\n",
    "    print(f\"\\nç©ºè¯„è®ºæ•°æ®é‡: {empty_mask.sum():,}\")\n",
    "    print(\"è¿™äº›ç©ºè¯„è®ºä¼šè¢«groupbyåˆå¹¶ï¼Œå¯¼è‡´è®¡æ•°å·®å¼‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€å¤„ç†ç©ºè¯„è®ºå¹¶é‡æ–°åˆ’åˆ†ã€‘\n",
      "ç©ºè¯„è®º: 2,485\n",
      "éç©ºè¯„è®º: 271,452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æœ€ç»ˆåˆ’åˆ†:\n",
      "è®­ç»ƒé›†: 219,151 (80.0%)\n",
      "éªŒè¯é›†: 27,393 (10.0%)\n",
      "æµ‹è¯•é›†: 27,393 (10.0%)\n",
      "æ€»è®¡: 273,937 = 273,937 âœ“\n"
     ]
    }
   ],
   "source": [
    "# 16. å¤„ç†ç©ºè¯„è®ºå¹¶é‡æ–°åˆ’åˆ†\n",
    "print(\"ã€å¤„ç†ç©ºè¯„è®ºå¹¶é‡æ–°åˆ’åˆ†ã€‘\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# åˆ†ç¦»ç©ºè¯„è®ºå’Œéç©ºè¯„è®º\n",
    "empty_mask = feature_df_clean['è¯„è®ºæ–‡æ¡ˆ'].isna()\n",
    "df_empty = feature_df_clean[empty_mask].copy()\n",
    "df_non_empty = feature_df_clean[~empty_mask].copy()\n",
    "\n",
    "print(f\"ç©ºè¯„è®º: {len(df_empty):,}\")\n",
    "print(f\"éç©ºè¯„è®º: {len(df_non_empty):,}\")\n",
    "\n",
    "# å¯¹éç©ºè¯„è®ºæŒ‰æ–‡æ¡ˆåˆ†ç»„\n",
    "df_non_empty = df_non_empty.sort_values(['è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´']).reset_index(drop=True)\n",
    "df_non_empty['æ–‡æ¡ˆé¡ºåº'] = df_non_empty.groupby('è¯„è®ºæ–‡æ¡ˆ').cumcount()\n",
    "\n",
    "first_occ = df_non_empty[df_non_empty['æ–‡æ¡ˆé¡ºåº'] == 0].copy()\n",
    "later_occ = df_non_empty[df_non_empty['æ–‡æ¡ˆé¡ºåº'] > 0].copy()\n",
    "\n",
    "# æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºå¿…é¡»åœ¨è®­ç»ƒé›†\n",
    "has_dup_mask = first_occ['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occ['è¯„è®ºæ–‡æ¡ˆ'])\n",
    "first_with_dup = first_occ[has_dup_mask].copy()\n",
    "first_no_dup = first_occ[~has_dup_mask].copy()\n",
    "\n",
    "# å¯åˆ†é…çš„æ•°æ®ï¼ˆåŒ…æ‹¬ç©ºè¯„è®ºï¼‰\n",
    "available = pd.concat([first_no_dup, later_occ, df_empty]).sample(frac=1, random_state=42)\n",
    "\n",
    "# è®¡ç®—å„é›†åˆå¤§å°\n",
    "total = len(feature_df_clean)\n",
    "val_size = int(total * 0.1)\n",
    "test_size = int(total * 0.1)\n",
    "\n",
    "# åˆ†é…\n",
    "val_df = available.iloc[:val_size].copy()\n",
    "test_df = available.iloc[val_size:val_size+test_size].copy()\n",
    "train_from_available = available.iloc[val_size+test_size:].copy()\n",
    "train_df = pd.concat([first_with_dup, train_from_available])\n",
    "\n",
    "print(f\"\\næœ€ç»ˆåˆ’åˆ†:\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_df):,} ({len(train_df)/total*100:.1f}%)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_df):,} ({len(val_df)/total*100:.1f}%)\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_df):,} ({len(test_df)/total*100:.1f}%)\")\n",
    "print(f\"æ€»è®¡: {len(train_df)+len(val_df)+len(test_df):,} = {total:,} âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ä¿å­˜æ•°æ®åˆ°æ ¹ç›®å½•ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ train.csv: 219,151 æ¡ (80.0%)\n",
      "âœ“ val.csv: 27,393 æ¡ (10.0%)\n",
      "âœ“ test.csv: 27,393 æ¡ (10.0%)\n",
      "å·²åˆ é™¤æ—§æ–‡ä»¶: D:/010_CodePrograms/L/LLM_su7/results/train.csv\n",
      "å·²åˆ é™¤æ—§æ–‡ä»¶: D:/010_CodePrograms/L/LLM_su7/results/val.csv\n"
     ]
    }
   ],
   "source": [
    "# 17. ä¿å­˜åˆ°æ ¹ç›®å½•\n",
    "print(\"ã€ä¿å­˜æ•°æ®åˆ°æ ¹ç›®å½•ã€‘\")\n",
    "\n",
    "ROOT_DIR = 'D:/010_CodePrograms/L/LLM_su7'\n",
    "\n",
    "# åˆ é™¤è¾…åŠ©åˆ—\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    if 'æ–‡æ¡ˆé¡ºåº' in df.columns:\n",
    "        df.drop(columns=['æ–‡æ¡ˆé¡ºåº'], inplace=True)\n",
    "\n",
    "# é‡ç½®ç´¢å¼•\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# ä¿å­˜\n",
    "train_df.to_csv(f'{ROOT_DIR}/train.csv', index=False, encoding='utf-8-sig')\n",
    "val_df.to_csv(f'{ROOT_DIR}/val.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv(f'{ROOT_DIR}/test.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"âœ“ train.csv: {len(train_df):,} æ¡ (80.0%)\")\n",
    "print(f\"âœ“ val.csv: {len(val_df):,} æ¡ (10.0%)\")\n",
    "print(f\"âœ“ test.csv: {len(test_df):,} æ¡ (10.0%)\")\n",
    "\n",
    "# åˆ é™¤resultsç›®å½•ä¸‹çš„æ—§æ–‡ä»¶\n",
    "import os\n",
    "old_files = [f'{RESULTS_DIR}/train.csv', f'{RESULTS_DIR}/val.csv']\n",
    "for f in old_files:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"å·²åˆ é™¤æ—§æ–‡ä»¶: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€å®Œæˆã€‘\n",
      "============================================================\n",
      "\n",
      "å·²åˆ›å»ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›† (8:1:1):\n",
      "â€¢ train.csv: 219,151 æ¡ (80.0%)\n",
      "â€¢ val.csv: 27,393 æ¡ (10.0%)\n",
      "â€¢ test.csv: 27,393 æ¡ (10.0%)\n",
      "\n",
      "ä¿å­˜ä½ç½®: D:/010_CodePrograms/L/LLM_su7/\n",
      "\n",
      "ç‰¹å¾åˆ— (12åˆ—):\n",
      "  è¯„è®ºæ–‡æ¡ˆ, å¾®åšæ–‡æ¡ˆ, æ ¹è¯„è®ºæ–‡æ¡ˆ, çˆ¶è¯„è®ºæ–‡æ¡ˆ, å‘å¸ƒæ—¶é—´,\n",
      "  ç”¨æˆ·æ€»è½¬å‘æ•°, ç”¨æˆ·æ€»è¯„è®ºæ•°, ç”¨æˆ·æ€»ç‚¹èµæ•°,\n",
      "  ç”¨æˆ·æ˜¯å¦è®¤è¯, æ˜¯å¦ä¸€çº§è¯„è®º, å­è¯„è®ºæ•°, ç‚¹èµæ•°\n",
      "\n",
      "åˆ’åˆ†è§„åˆ™:\n",
      "â€¢ è¯„è®ºæ–‡æ¡ˆé‡å¤æ—¶ï¼Œæ—¶é—´ä¸Šé¦–æ¬¡å‡ºç°çš„å¿…é¡»åœ¨è®­ç»ƒé›† âœ“\n",
      "â€¢ ç©ºè¯„è®º(2,485æ¡)éšæœºåˆ†é…åˆ°å„é›†åˆ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ã€å®Œæˆã€‘\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "å·²åˆ›å»ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›† (8:1:1):\n",
    "â€¢ train.csv: {len(train_df):,} æ¡ (80.0%)\n",
    "â€¢ val.csv: {len(val_df):,} æ¡ (10.0%)\n",
    "â€¢ test.csv: {len(test_df):,} æ¡ (10.0%)\n",
    "\n",
    "ä¿å­˜ä½ç½®: D:/010_CodePrograms/L/LLM_su7/\n",
    "\n",
    "ç‰¹å¾åˆ— (12åˆ—):\n",
    "  è¯„è®ºæ–‡æ¡ˆ, å¾®åšæ–‡æ¡ˆ, æ ¹è¯„è®ºæ–‡æ¡ˆ, çˆ¶è¯„è®ºæ–‡æ¡ˆ, å‘å¸ƒæ—¶é—´,\n",
    "  ç”¨æˆ·æ€»è½¬å‘æ•°, ç”¨æˆ·æ€»è¯„è®ºæ•°, ç”¨æˆ·æ€»ç‚¹èµæ•°,\n",
    "  ç”¨æˆ·æ˜¯å¦è®¤è¯, æ˜¯å¦ä¸€çº§è¯„è®º, å­è¯„è®ºæ•°, ç‚¹èµæ•°\n",
    "\n",
    "åˆ’åˆ†è§„åˆ™:\n",
    "â€¢ è¯„è®ºæ–‡æ¡ˆé‡å¤æ—¶ï¼Œæ—¶é—´ä¸Šé¦–æ¬¡å‡ºç°çš„å¿…é¡»åœ¨è®­ç»ƒé›† âœ“\n",
    "â€¢ ç©ºè¯„è®º(2,485æ¡)éšæœºåˆ†é…åˆ°å„é›†åˆ\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€é‡æ–°å¤„ç†æ•°æ®ã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹è¯„è®ºæ•°æ®: 273,937 æ¡\n",
      "ç©ºè¯„è®ºæ•°: 2,485\n",
      "å»é™¤ç©ºè¯„è®ºå: 271,452 æ¡\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æ›´æ–°ä¿å­˜: D:/010_CodePrograms/L/LLM_su7/results/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv\n"
     ]
    }
   ],
   "source": [
    "# 19. é‡æ–°å¤„ç†æ•°æ®ï¼šå»é™¤ç©ºè¯„è®º\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€é‡æ–°å¤„ç†æ•°æ®ã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# é‡æ–°åŠ è½½è¯„è®ºæ•°æ®\n",
    "comments_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"åŸå§‹è¯„è®ºæ•°æ®: {len(comments_df):,} æ¡\")\n",
    "\n",
    "# å»é™¤ç©ºè¯„è®º\n",
    "empty_mask = comments_df['è¯„è®ºå†…å®¹'].isna() | (comments_df['è¯„è®ºå†…å®¹'] == '')\n",
    "print(f\"ç©ºè¯„è®ºæ•°: {empty_mask.sum():,}\")\n",
    "\n",
    "comments_df = comments_df[~empty_mask].reset_index(drop=True)\n",
    "print(f\"å»é™¤ç©ºè¯„è®ºå: {len(comments_df):,} æ¡\")\n",
    "\n",
    "# é‡æ–°ä¿å­˜\n",
    "comments_df.to_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"å·²æ›´æ–°ä¿å­˜: {RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€å»é™¤ç©ºè¯„è®ºã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹æ•°æ®: 271,452 æ¡\n",
      "è¯„è®ºå†…å®¹ä¸ºNaN: 0\n",
      "è¯„è®ºå†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²: 0\n",
      "\n",
      "å»é™¤ç©ºè¯„è®ºå: 271,452 æ¡\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²ä¿å­˜: D:/010_CodePrograms/L/LLM_su7/results/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv\n"
     ]
    }
   ],
   "source": [
    "# 19. å»é™¤ç©ºè¯„è®ºå¹¶é‡æ–°ä¿å­˜\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€å»é™¤ç©ºè¯„è®ºã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# é‡æ–°åŠ è½½åŸå§‹å»é‡æ•°æ®\n",
    "comments_raw = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"åŸå§‹æ•°æ®: {len(comments_raw):,} æ¡\")\n",
    "\n",
    "# æ£€æŸ¥ç©ºè¯„è®º\n",
    "null_count = comments_raw['è¯„è®ºå†…å®¹'].isna().sum()\n",
    "empty_count = (comments_raw['è¯„è®ºå†…å®¹'] == '').sum()\n",
    "print(f\"è¯„è®ºå†…å®¹ä¸ºNaN: {null_count:,}\")\n",
    "print(f\"è¯„è®ºå†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²: {empty_count:,}\")\n",
    "\n",
    "# å»é™¤ç©ºè¯„è®º\n",
    "comments_clean = comments_raw[comments_raw['è¯„è®ºå†…å®¹'].notna() & (comments_raw['è¯„è®ºå†…å®¹'] != '')].copy()\n",
    "print(f\"\\nå»é™¤ç©ºè¯„è®ºå: {len(comments_clean):,} æ¡\")\n",
    "\n",
    "# é‡æ–°ä¿å­˜\n",
    "comments_clean.to_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"å·²ä¿å­˜: {RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€é‡æ–°æ„å»ºç‰¹å¾è¡¨ã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯„è®ºæ•°æ®: 271,452 æ¡\n",
      "å¾®åšæ•°æ®: 4,186 æ¡\n",
      "\n",
      "å¾®åšç‰¹å¾æ˜ å°„æ•°: 4,186\n",
      "                                                                                     å¾®åšæ–‡æ¡ˆ  \\\n",
      "weibo_url                                                                                   \n",
      "https://weibo.com/7871239944/PkvsRdOvf  ä¼—æ‰€å‘¨çŸ¥ï¼Œå°ç±³æ±½è½¦çš„å¹¿å‘Šéƒ½æ˜¯è½¦ä¸»æ‹çš„ğŸ‘ ä¸€èµ·æ¥æ¬£èµå¤§ç‰‡ï¼Œå°ç±³SU7 Ultraè½¦ä¸»å‡ºå“ã€‚ L...   \n",
      "https://weibo.com/7747056179/Pkpf5e7ul                      å°ç±³su7æ˜¯ä»–çš„å‘½å§ï¼Œæœ‰åŒæ¬¾é˜Ÿå‹å— LYTBäº®çœ¼çš„å¾®åšè§†é¢‘   \n",
      "\n",
      "                                        å¾®åšè½¬å‘æ•°  å¾®åšè¯„è®ºæ•°   å¾®åšç‚¹èµæ•°  \n",
      "weibo_url                                                     \n",
      "https://weibo.com/7871239944/PkvsRdOvf     48    105  2017.0  \n",
      "https://weibo.com/7747056179/Pkpf5e7ul     30    280  1619.0  \n"
     ]
    }
   ],
   "source": [
    "# 20. é‡æ–°åŠ è½½å¹¶æ„å»ºç‰¹å¾ï¼ˆåŒ…å«å¾®åšè½¬å‘æ•°/è¯„è®ºæ•°/ç‚¹èµæ•°ï¼‰\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€é‡æ–°æ„å»ºç‰¹å¾è¡¨ã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŠ è½½è¯„è®ºæ•°æ®\n",
    "comments_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"è¯„è®ºæ•°æ®: {len(comments_df):,} æ¡\")\n",
    "\n",
    "# åŠ è½½å¾®åšæ•°æ®ï¼ˆè·å–è½¬å‘æ•°/è¯„è®ºæ•°/ç‚¹èµæ•°ï¼‰\n",
    "weibo_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åš_å»é‡.csv', encoding='utf-8-sig')\n",
    "print(f\"å¾®åšæ•°æ®: {len(weibo_df):,} æ¡\")\n",
    "\n",
    "# åˆ›å»ºå¾®åšç‰¹å¾æ˜ å°„\n",
    "weibo_features = weibo_df.set_index('weibo_url')[['weibo_content', 'repost_count', 'comment_count', 'like_count']]\n",
    "weibo_features.columns = ['å¾®åšæ–‡æ¡ˆ', 'å¾®åšè½¬å‘æ•°', 'å¾®åšè¯„è®ºæ•°', 'å¾®åšç‚¹èµæ•°']\n",
    "\n",
    "print(f\"\\nå¾®åšç‰¹å¾æ˜ å°„æ•°: {len(weibo_features):,}\")\n",
    "print(weibo_features.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€æ„å»ºå®Œæ•´ç‰¹å¾è¡¨ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾æ„å»ºå®Œæˆï¼Œæ•°æ®é‡: 284,109\n"
     ]
    }
   ],
   "source": [
    "# 21. æ„å»ºå®Œæ•´ç‰¹å¾è¡¨\n",
    "print(\"ã€æ„å»ºå®Œæ•´ç‰¹å¾è¡¨ã€‘\")\n",
    "\n",
    "# æ ‡å‡†åŒ–è¯„è®ºID\n",
    "def normalize_id(id_val):\n",
    "    if pd.isna(id_val):\n",
    "        return None\n",
    "    return str(int(float(id_val)))\n",
    "\n",
    "comments_df['è¯„è®ºID_str'] = comments_df['è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['æ ¹è¯„è®ºID_str'] = comments_df['æ ¹è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['çˆ¶è¯„è®ºID_str'] = comments_df['çˆ¶è¯„è®ºID'].apply(normalize_id)\n",
    "\n",
    "# åˆ›å»ºè¯„è®ºID -> è¯„è®ºå†…å®¹æ˜ å°„\n",
    "comment_content_map = dict(zip(comments_df['è¯„è®ºID_str'], comments_df['è¯„è®ºå†…å®¹']))\n",
    "\n",
    "# å…³è”å¾®åšç‰¹å¾\n",
    "comments_df = comments_df.merge(\n",
    "    weibo_features.reset_index(), \n",
    "    left_on='åŸæ–‡é“¾æ¥', \n",
    "    right_on='weibo_url', \n",
    "    how='left'\n",
    ").drop(columns=['weibo_url'])\n",
    "\n",
    "# æ·»åŠ æ ¹è¯„è®ºæ–‡æ¡ˆ\n",
    "comments_df['æ ¹è¯„è®ºæ–‡æ¡ˆ'] = comments_df['æ ¹è¯„è®ºID_str'].map(comment_content_map)\n",
    "\n",
    "# æ·»åŠ çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "def get_parent_content(row):\n",
    "    if row['æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º']:\n",
    "        return row['å¾®åšæ–‡æ¡ˆ']\n",
    "    else:\n",
    "        return comment_content_map.get(row['çˆ¶è¯„è®ºID_str'], None)\n",
    "\n",
    "comments_df['çˆ¶è¯„è®ºæ–‡æ¡ˆ'] = comments_df.apply(get_parent_content, axis=1)\n",
    "\n",
    "print(f\"ç‰¹å¾æ„å»ºå®Œæˆï¼Œæ•°æ®é‡: {len(comments_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€æ£€æŸ¥æ•°æ®è†¨èƒ€é—®é¢˜ã€‘\n",
      "åŸè¯„è®ºæ•°: 271,452\n",
      "mergeå: 284,109\n",
      "\n",
      "å¾®åšURLé‡å¤æ•°: 33\n",
      "å»é‡åå¾®åšæ•°: 4,153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "é‡æ–°mergeåæ•°æ®é‡: 271,452\n"
     ]
    }
   ],
   "source": [
    "# 22. æ£€æŸ¥mergeé—®é¢˜\n",
    "print(\"ã€æ£€æŸ¥æ•°æ®è†¨èƒ€é—®é¢˜ã€‘\")\n",
    "print(f\"åŸè¯„è®ºæ•°: 271,452\")\n",
    "print(f\"mergeå: {len(comments_df):,}\")\n",
    "\n",
    "# æ£€æŸ¥å¾®åšURLæ˜¯å¦æœ‰é‡å¤\n",
    "dup_urls = weibo_df['weibo_url'].duplicated().sum()\n",
    "print(f\"\\nå¾®åšURLé‡å¤æ•°: {dup_urls}\")\n",
    "\n",
    "# é‡æ–°å¤„ç†ï¼šå…ˆå»é‡å¾®åšæ•°æ®\n",
    "weibo_dedup = weibo_df.drop_duplicates(subset=['weibo_url'], keep='first')\n",
    "print(f\"å»é‡åå¾®åšæ•°: {len(weibo_dedup):,}\")\n",
    "\n",
    "# é‡æ–°åŠ è½½è¯„è®ºæ•°æ®å¹¶merge\n",
    "comments_df = pd.read_csv(f'{RESULTS_DIR}/çƒ­é—¨å¾®åšè¯„è®ºæ•°æ®_å»é‡.csv', encoding='utf-8-sig')\n",
    "\n",
    "weibo_features = weibo_dedup.set_index('weibo_url')[['weibo_content', 'repost_count', 'comment_count', 'like_count']]\n",
    "weibo_features.columns = ['å¾®åšæ–‡æ¡ˆ', 'å¾®åšè½¬å‘æ•°', 'å¾®åšè¯„è®ºæ•°', 'å¾®åšç‚¹èµæ•°']\n",
    "\n",
    "comments_df = comments_df.merge(\n",
    "    weibo_features.reset_index(), \n",
    "    left_on='åŸæ–‡é“¾æ¥', \n",
    "    right_on='weibo_url', \n",
    "    how='left'\n",
    ").drop(columns=['weibo_url'])\n",
    "\n",
    "print(f\"\\né‡æ–°mergeåæ•°æ®é‡: {len(comments_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ç»§ç»­æ„å»ºç‰¹å¾ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾æ„å»ºå®Œæˆ\n",
      "\n",
      "ç¼ºå¤±å€¼ç»Ÿè®¡:\n",
      "  å¾®åšæ–‡æ¡ˆç¼ºå¤±: 34\n",
      "  å¾®åšè½¬å‘æ•°ç¼ºå¤±: 0\n",
      "  æ ¹è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: 156,171 (ä¸€çº§è¯„è®ºæ— æ ¹è¯„è®º)\n",
      "  çˆ¶è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: 1,316\n"
     ]
    }
   ],
   "source": [
    "# 23. ç»§ç»­æ„å»ºç‰¹å¾\n",
    "print(\"ã€ç»§ç»­æ„å»ºç‰¹å¾ã€‘\")\n",
    "\n",
    "# æ ‡å‡†åŒ–è¯„è®ºID\n",
    "comments_df['è¯„è®ºID_str'] = comments_df['è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['æ ¹è¯„è®ºID_str'] = comments_df['æ ¹è¯„è®ºID'].apply(normalize_id)\n",
    "comments_df['çˆ¶è¯„è®ºID_str'] = comments_df['çˆ¶è¯„è®ºID'].apply(normalize_id)\n",
    "\n",
    "# åˆ›å»ºè¯„è®ºID -> è¯„è®ºå†…å®¹æ˜ å°„\n",
    "comment_content_map = dict(zip(comments_df['è¯„è®ºID_str'], comments_df['è¯„è®ºå†…å®¹']))\n",
    "\n",
    "# æ·»åŠ æ ¹è¯„è®ºæ–‡æ¡ˆ\n",
    "comments_df['æ ¹è¯„è®ºæ–‡æ¡ˆ'] = comments_df['æ ¹è¯„è®ºID_str'].map(comment_content_map)\n",
    "\n",
    "# æ·»åŠ çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "comments_df['çˆ¶è¯„è®ºæ–‡æ¡ˆ'] = comments_df.apply(get_parent_content, axis=1)\n",
    "\n",
    "# å¤„ç†ç”¨æˆ·ç»Ÿè®¡æ•°æ®\n",
    "comments_df['ç”¨æˆ·æ€»è½¬å‘æ•°_clean'] = comments_df['ç”¨æˆ·æ€»è½¬å‘æ•°'].apply(clean_number)\n",
    "comments_df['ç”¨æˆ·æ€»è¯„è®ºæ•°_clean'] = comments_df['ç”¨æˆ·æ€»è¯„è®ºæ•°'].apply(clean_number)\n",
    "comments_df['ç”¨æˆ·æ€»ç‚¹èµæ•°_clean'] = comments_df['ç”¨æˆ·æ€»ç‚¹èµæ•°'].apply(clean_number)\n",
    "\n",
    "print(f\"ç‰¹å¾æ„å»ºå®Œæˆ\")\n",
    "print(f\"\\nç¼ºå¤±å€¼ç»Ÿè®¡:\")\n",
    "print(f\"  å¾®åšæ–‡æ¡ˆç¼ºå¤±: {comments_df['å¾®åšæ–‡æ¡ˆ'].isna().sum():,}\")\n",
    "print(f\"  å¾®åšè½¬å‘æ•°ç¼ºå¤±: {comments_df['å¾®åšè½¬å‘æ•°'].isna().sum():,}\")\n",
    "print(f\"  æ ¹è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: {comments_df['æ ¹è¯„è®ºæ–‡æ¡ˆ'].isna().sum():,} (ä¸€çº§è¯„è®ºæ— æ ¹è¯„è®º)\")\n",
    "print(f\"  çˆ¶è¯„è®ºæ–‡æ¡ˆç¼ºå¤±: {comments_df['çˆ¶è¯„è®ºæ–‡æ¡ˆ'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€é€‰æ‹©ç‰¹å¾åˆ—ã€‘\n",
      "ç‰¹å¾è¡¨å¤§å°: 271,452 æ¡\n",
      "ç‰¹å¾åˆ— (15åˆ—): ['è¯„è®ºæ–‡æ¡ˆ', 'å¾®åšæ–‡æ¡ˆ', 'æ ¹è¯„è®ºæ–‡æ¡ˆ', 'çˆ¶è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´', 'ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°', 'ç”¨æˆ·æ˜¯å¦è®¤è¯', 'æ˜¯å¦ä¸€çº§è¯„è®º', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°', 'å¾®åšè½¬å‘æ•°', 'å¾®åšè¯„è®ºæ•°', 'å¾®åšç‚¹èµæ•°']\n"
     ]
    }
   ],
   "source": [
    "# 24. é€‰æ‹©ç‰¹å¾åˆ—\n",
    "print(\"ã€é€‰æ‹©ç‰¹å¾åˆ—ã€‘\")\n",
    "\n",
    "feature_df = comments_df[[\n",
    "    # è¯„è®ºæœ¬èº«æ–‡æ¡ˆ\n",
    "    'è¯„è®ºå†…å®¹',\n",
    "    # å¾®åš/æ ¹è¯„è®º/çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "    'å¾®åšæ–‡æ¡ˆ',\n",
    "    'æ ¹è¯„è®ºæ–‡æ¡ˆ',\n",
    "    'çˆ¶è¯„è®ºæ–‡æ¡ˆ',\n",
    "    # æ—¶é—´\n",
    "    'å‘å¸ƒæ—¶é—´',\n",
    "    # ä½œè€…ç»Ÿè®¡\n",
    "    'ç”¨æˆ·æ€»è½¬å‘æ•°_clean',\n",
    "    'ç”¨æˆ·æ€»è¯„è®ºæ•°_clean', \n",
    "    'ç”¨æˆ·æ€»ç‚¹èµæ•°_clean',\n",
    "    # ç”¨æˆ·æ˜¯å¦è®¤è¯\n",
    "    'ç”¨æˆ·è®¤è¯',\n",
    "    # æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º\n",
    "    'æ˜¯å¦æ˜¯ä¸€çº§è¯„è®º',\n",
    "    # è¯„è®ºæœ¬èº«æŒ‡æ ‡\n",
    "    'å­è¯„è®ºæ•°',\n",
    "    'ç‚¹èµæ•°',\n",
    "    # å¾®åšæŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰\n",
    "    'å¾®åšè½¬å‘æ•°',\n",
    "    'å¾®åšè¯„è®ºæ•°',\n",
    "    'å¾®åšç‚¹èµæ•°'\n",
    "]].copy()\n",
    "\n",
    "# é‡å‘½ååˆ—\n",
    "feature_df.columns = [\n",
    "    'è¯„è®ºæ–‡æ¡ˆ', 'å¾®åšæ–‡æ¡ˆ', 'æ ¹è¯„è®ºæ–‡æ¡ˆ', 'çˆ¶è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´',\n",
    "    'ç”¨æˆ·æ€»è½¬å‘æ•°', 'ç”¨æˆ·æ€»è¯„è®ºæ•°', 'ç”¨æˆ·æ€»ç‚¹èµæ•°',\n",
    "    'ç”¨æˆ·æ˜¯å¦è®¤è¯', 'æ˜¯å¦ä¸€çº§è¯„è®º', 'å­è¯„è®ºæ•°', 'ç‚¹èµæ•°',\n",
    "    'å¾®åšè½¬å‘æ•°', 'å¾®åšè¯„è®ºæ•°', 'å¾®åšç‚¹èµæ•°'\n",
    "]\n",
    "\n",
    "print(f\"ç‰¹å¾è¡¨å¤§å°: {len(feature_df):,} æ¡\")\n",
    "print(f\"ç‰¹å¾åˆ— ({len(feature_df.columns)}åˆ—): {list(feature_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€åˆ’åˆ†æ•°æ®é›† 8:1:1ã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦–æ¬¡å‡ºç°ä¸”æœ‰é‡å¤ï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰: 5,623\n",
      "é¦–æ¬¡å‡ºç°ä¸”æ— é‡å¤ï¼ˆå¯åˆ†é…ï¼‰: 240,467\n",
      "é‡å¤å‡ºç°ï¼ˆå¯åˆ†é…ï¼‰: 25,362\n",
      "\n",
      "åˆ’åˆ†ç»“æœ:\n",
      "è®­ç»ƒé›†: 217,162 (80.0%)\n",
      "éªŒè¯é›†: 27,145 (10.0%)\n",
      "æµ‹è¯•é›†: 27,145 (10.0%)\n",
      "æ€»è®¡: 271,452 = 271,452 âœ“\n"
     ]
    }
   ],
   "source": [
    "# 25. åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›† (8:1:1)\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€åˆ’åˆ†æ•°æ®é›† 8:1:1ã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# è½¬æ¢æ—¶é—´åˆ—\n",
    "feature_df['å‘å¸ƒæ—¶é—´'] = pd.to_datetime(feature_df['å‘å¸ƒæ—¶é—´'])\n",
    "\n",
    "# æŒ‰è¯„è®ºæ–‡æ¡ˆå’Œæ—¶é—´æ’åº\n",
    "feature_df = feature_df.sort_values(['è¯„è®ºæ–‡æ¡ˆ', 'å‘å¸ƒæ—¶é—´']).reset_index(drop=True)\n",
    "feature_df['æ–‡æ¡ˆé¡ºåº'] = feature_df.groupby('è¯„è®ºæ–‡æ¡ˆ').cumcount()\n",
    "\n",
    "# åˆ†ç¦»é¦–æ¬¡å‡ºç°å’Œé‡å¤å‡ºç°\n",
    "first_occ = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] == 0].copy()\n",
    "later_occ = feature_df[feature_df['æ–‡æ¡ˆé¡ºåº'] > 0].copy()\n",
    "\n",
    "# æœ‰é‡å¤çš„é¦–æ¬¡è¯„è®ºï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰\n",
    "has_dup_mask = first_occ['è¯„è®ºæ–‡æ¡ˆ'].isin(later_occ['è¯„è®ºæ–‡æ¡ˆ'])\n",
    "first_with_dup = first_occ[has_dup_mask].copy()\n",
    "first_no_dup = first_occ[~has_dup_mask].copy()\n",
    "\n",
    "print(f\"é¦–æ¬¡å‡ºç°ä¸”æœ‰é‡å¤ï¼ˆå¿…é¡»åœ¨è®­ç»ƒé›†ï¼‰: {len(first_with_dup):,}\")\n",
    "print(f\"é¦–æ¬¡å‡ºç°ä¸”æ— é‡å¤ï¼ˆå¯åˆ†é…ï¼‰: {len(first_no_dup):,}\")\n",
    "print(f\"é‡å¤å‡ºç°ï¼ˆå¯åˆ†é…ï¼‰: {len(later_occ):,}\")\n",
    "\n",
    "# å¯åˆ†é…çš„æ•°æ®\n",
    "available = pd.concat([first_no_dup, later_occ]).sample(frac=1, random_state=42)\n",
    "\n",
    "# è®¡ç®—å„é›†åˆå¤§å°\n",
    "total = len(feature_df)\n",
    "val_size = int(total * 0.1)\n",
    "test_size = int(total * 0.1)\n",
    "\n",
    "# åˆ†é…\n",
    "val_df = available.iloc[:val_size].copy()\n",
    "test_df = available.iloc[val_size:val_size+test_size].copy()\n",
    "train_from_available = available.iloc[val_size+test_size:].copy()\n",
    "train_df = pd.concat([first_with_dup, train_from_available])\n",
    "\n",
    "print(f\"\\nåˆ’åˆ†ç»“æœ:\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_df):,} ({len(train_df)/total*100:.1f}%)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_df):,} ({len(val_df)/total*100:.1f}%)\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_df):,} ({len(test_df)/total*100:.1f}%)\")\n",
    "print(f\"æ€»è®¡: {len(train_df)+len(val_df)+len(test_df):,} = {total:,} âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€ä¿å­˜æ•°æ®ã€‘\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVæ ¼å¼:\n",
      "  âœ“ train.csv: 217,162 æ¡\n",
      "  âœ“ val.csv: 27,145 æ¡\n",
      "  âœ“ test.csv: 27,145 æ¡\n",
      "\n",
      "PKLæ ¼å¼:\n",
      "  âœ“ train.pkl: 217,162 æ¡\n",
      "  âœ“ val.pkl: 27,145 æ¡\n",
      "  âœ“ test.pkl: 27,145 æ¡\n",
      "\n",
      "train: CSV=220.1MB, PKL=36.4MB (èŠ‚çœ83%)\n",
      "\n",
      "val: CSV=27.8MB, PKL=6.7MB (èŠ‚çœ76%)\n",
      "\n",
      "test: CSV=27.4MB, PKL=6.7MB (èŠ‚çœ76%)\n"
     ]
    }
   ],
   "source": [
    "# 26. ä¿å­˜ä¸ºCSVå’ŒPKLä¸¤ç§æ ¼å¼\n",
    "print(\"=\" * 60)\n",
    "print(\"ã€ä¿å­˜æ•°æ®ã€‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ROOT_DIR = 'D:/010_CodePrograms/L/LLM_su7'\n",
    "\n",
    "# åˆ é™¤è¾…åŠ©åˆ—å¹¶é‡ç½®ç´¢å¼•\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    if 'æ–‡æ¡ˆé¡ºåº' in df.columns:\n",
    "        df.drop(columns=['æ–‡æ¡ˆé¡ºåº'], inplace=True)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# ä¿å­˜CSVæ ¼å¼\n",
    "train_df.to_csv(f'{ROOT_DIR}/train.csv', index=False, encoding='utf-8-sig')\n",
    "val_df.to_csv(f'{ROOT_DIR}/val.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv(f'{ROOT_DIR}/test.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"CSVæ ¼å¼:\")\n",
    "print(f\"  âœ“ train.csv: {len(train_df):,} æ¡\")\n",
    "print(f\"  âœ“ val.csv: {len(val_df):,} æ¡\")\n",
    "print(f\"  âœ“ test.csv: {len(test_df):,} æ¡\")\n",
    "\n",
    "# ä¿å­˜PKLæ ¼å¼\n",
    "train_df.to_pickle(f'{ROOT_DIR}/train.pkl')\n",
    "val_df.to_pickle(f'{ROOT_DIR}/val.pkl')\n",
    "test_df.to_pickle(f'{ROOT_DIR}/test.pkl')\n",
    "\n",
    "print(\"\\nPKLæ ¼å¼:\")\n",
    "print(f\"  âœ“ train.pkl: {len(train_df):,} æ¡\")\n",
    "print(f\"  âœ“ val.pkl: {len(val_df):,} æ¡\")\n",
    "print(f\"  âœ“ test.pkl: {len(test_df):,} æ¡\")\n",
    "\n",
    "# æ¯”è¾ƒæ–‡ä»¶å¤§å°\n",
    "import os\n",
    "for name in ['train', 'val', 'test']:\n",
    "    csv_size = os.path.getsize(f'{ROOT_DIR}/{name}.csv') / 1024 / 1024\n",
    "    pkl_size = os.path.getsize(f'{ROOT_DIR}/{name}.pkl') / 1024 / 1024\n",
    "    print(f\"\\n{name}: CSV={csv_size:.1f}MB, PKL={pkl_size:.1f}MB (èŠ‚çœ{(1-pkl_size/csv_size)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ã€å®Œæˆã€‘\n",
      "============================================================\n",
      "\n",
      "æ•°æ®é›†åˆ’åˆ† (8:1:1):\n",
      "  è®­ç»ƒé›†: 217,162 æ¡ (80.0%)\n",
      "  éªŒè¯é›†: 27,145 æ¡ (10.0%)\n",
      "  æµ‹è¯•é›†: 27,145 æ¡ (10.0%)\n",
      "\n",
      "ä¿å­˜ä½ç½®: D:/010_CodePrograms/L/LLM_su7/\n",
      "  CSV: train.csv, val.csv, test.csv\n",
      "  PKL: train.pkl, val.pkl, test.pkl\n",
      "\n",
      "ç‰¹å¾åˆ— (15åˆ—):\n",
      "  æ–‡æ¡ˆç±»: è¯„è®ºæ–‡æ¡ˆ, å¾®åšæ–‡æ¡ˆ, æ ¹è¯„è®ºæ–‡æ¡ˆ, çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
      "  æ—¶é—´: å‘å¸ƒæ—¶é—´\n",
      "  ç”¨æˆ·ç‰¹å¾: ç”¨æˆ·æ€»è½¬å‘æ•°, ç”¨æˆ·æ€»è¯„è®ºæ•°, ç”¨æˆ·æ€»ç‚¹èµæ•°, ç”¨æˆ·æ˜¯å¦è®¤è¯\n",
      "  è¯„è®ºç‰¹å¾: æ˜¯å¦ä¸€çº§è¯„è®º, å­è¯„è®ºæ•°, ç‚¹èµæ•°\n",
      "  å¾®åšç‰¹å¾: å¾®åšè½¬å‘æ•°, å¾®åšè¯„è®ºæ•°, å¾®åšç‚¹èµæ•° (æ–°å¢)\n",
      "\n",
      "æ–‡ä»¶å¤§å°å¯¹æ¯”:\n",
      "  CSVæ€»è®¡: 275.3MB\n",
      "  PKLæ€»è®¡: 49.8MB (èŠ‚çœçº¦80%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ã€å®Œæˆã€‘\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "æ•°æ®é›†åˆ’åˆ† (8:1:1):\n",
    "  è®­ç»ƒé›†: {len(train_df):,} æ¡ (80.0%)\n",
    "  éªŒè¯é›†: {len(val_df):,} æ¡ (10.0%)\n",
    "  æµ‹è¯•é›†: {len(test_df):,} æ¡ (10.0%)\n",
    "\n",
    "ä¿å­˜ä½ç½®: D:/010_CodePrograms/L/LLM_su7/\n",
    "  CSV: train.csv, val.csv, test.csv\n",
    "  PKL: train.pkl, val.pkl, test.pkl\n",
    "\n",
    "ç‰¹å¾åˆ— (15åˆ—):\n",
    "  æ–‡æ¡ˆç±»: è¯„è®ºæ–‡æ¡ˆ, å¾®åšæ–‡æ¡ˆ, æ ¹è¯„è®ºæ–‡æ¡ˆ, çˆ¶è¯„è®ºæ–‡æ¡ˆ\n",
    "  æ—¶é—´: å‘å¸ƒæ—¶é—´\n",
    "  ç”¨æˆ·ç‰¹å¾: ç”¨æˆ·æ€»è½¬å‘æ•°, ç”¨æˆ·æ€»è¯„è®ºæ•°, ç”¨æˆ·æ€»ç‚¹èµæ•°, ç”¨æˆ·æ˜¯å¦è®¤è¯\n",
    "  è¯„è®ºç‰¹å¾: æ˜¯å¦ä¸€çº§è¯„è®º, å­è¯„è®ºæ•°, ç‚¹èµæ•°\n",
    "  å¾®åšç‰¹å¾: å¾®åšè½¬å‘æ•°, å¾®åšè¯„è®ºæ•°, å¾®åšç‚¹èµæ•° (æ–°å¢)\n",
    "\n",
    "æ–‡ä»¶å¤§å°å¯¹æ¯”:\n",
    "  CSVæ€»è®¡: {220.1+27.8+27.4:.1f}MB\n",
    "  PKLæ€»è®¡: {36.4+6.7+6.7:.1f}MB (èŠ‚çœçº¦80%)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
